# Bedrock Converse

## Temel Kullan覺m

#### Bir istemle `complete` 癟ar覺s覺 yap覺n

Eer bu Not Defterini colab 羹zerinde a癟覺yorsan覺z, muhtemelen LlamaIndex'i  kurman覺z gerekecektir.

```python
%pip install llama-index-llms-bedrock-converse
```

```python
!pip install llama-index
```

```python
from llama_index.llms.bedrock_converse import BedrockConverse

profile_name = "AWS profil ad覺n覺z"
resp = BedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    profile_name=profile_name,
).complete("Paul Graham bir ")
```

```python
print(resp)
```

#### Bir mesaj listesiyle `chat` 癟ar覺s覺 yap覺n

```python
from llama_index.core.llms import ChatMessage
from llama_index.llms.bedrock_converse import BedrockConverse

messages = [
    ChatMessage(
        role="system", content="Renkli bir kiilie sahip bir korsans覺n"
    ),
    ChatMessage(role="user", content="Bana bir hikaye anlat"),
]

resp = BedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    profile_name=profile_name,
).chat(messages)
```

```python
print(resp)
```

## Ak覺 (Streaming)

`stream_complete` biti noktas覺n覺 (endpoint) kullanma

```python
from llama_index.llms.bedrock_converse import BedrockConverse

llm = BedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    profile_name=profile_name,
)
resp = llm.stream_complete("Paul Graham bir ")
```

```python
for r in resp:
    print(r.delta, end="")
```

`stream_chat` biti noktas覺n覺 kullanma

```python
from llama_index.llms.bedrock_converse import BedrockConverse

llm = BedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    profile_name=profile_name,
)
messages = [
    ChatMessage(
        role="system", content="Renkli bir kiilie sahip bir korsans覺n"
    ),
    ChatMessage(role="user", content="Bana bir hikaye anlat"),
]
resp = llm.stream_chat(messages)
```

```python
for r in resp:
    print(r.delta, end="")
```

## Modeli Yap覺land覺rma

```python
from llama_index.llms.bedrock_converse import BedrockConverse

llm = BedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    profile_name=profile_name,
)
```

```python
resp = llm.complete("Paul Graham bir ")
```

```python
print(resp)
```

## Eriim Anahtarlar覺 (Access Keys) ile Bedrock'a Balanma

```python
from llama_index.llms.bedrock_converse import BedrockConverse

llm = BedrockConverse(
    model="us.amazon.nova-lite-v1:0",
    aws_access_key_id="Kullan覺lacak AWS Eriim Anahtar Kimlii (Access Key ID)",
    aws_secret_access_key="Kullan覺lacak AWS Gizli Eriim Anahtar覺 (Secret Access Key)",
    aws_session_token="Kullan覺lacak AWS Oturum Belirteci (Session Token)",
    region_name="Kullan覺lacak AWS B繹lgesi, 繹rn. us-east-1",
)

resp = llm.complete("Paul Graham bir ")
```

```python
print(resp)
```

## Fonksiyon a覺rma (Function Calling)

Claude, Command ve Mistral Large modelleri, AWS Bedrock Converse arac覺l覺覺yla yerel fonksiyon 癟a覺rmay覺 destekler. `llm` 羹zerindeki `predict_and_call` fonksiyonu ile LlamaIndex ara癟lar覺yla kusursuz bir entegrasyon salan覺r.

Bu, kullan覺c覺n覺n herhangi bir arac覺 eklemesine ve hangi ara癟lar覺n 癟ar覺laca覺na (varsa) LLM'nin karar vermesine olanak tan覺r.

Eer fonksiyon 癟a覺rmay覺 bir arac覺 d繹ng羹s羹n羹n (agentic loop) par癟as覺 olarak ger癟ekletirmek istiyorsan覺z, bunun yerine [arac覺 k覺lavuzlar覺m覺za](https://docs.llamaindex.ai/en/latest/module_guides/deploying/agents/) g繹z at覺n.

**NOT**: AWS Bedrock'taki modellerin t羹m羹 fonksiyon 癟a覺rmay覺 ve Converse API'yi desteklemez. [Her bir LLM'nin kullan覺labilir 繹zelliklerini buradan kontrol edin](https://docs.aws.amazon.com/bedrock/latest/userguide/models-features.html).

```python
from llama_index.llms.bedrock_converse import BedrockConverse
from llama_index.core.tools import FunctionTool

def multiply(a: int, b: int) -> int:
    """襤ki tamsay覺y覺 癟arpar ve sonu癟 tamsay覺s覺n覺 d繹nd羹r羹r"""
    return a * b

def mystery(a: int, b: int) -> int:
    """襤ki tamsay覺 羹zerinde gizemli fonksiyon."""
    return a * b + a + b

mystery_tool = FunctionTool.from_defaults(fn=mystery)
multiply_tool = FunctionTool.from_defaults(fn=multiply)

llm = BedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    profile_name=profile_name,
)
```

```python
response = llm.predict_and_call(
    [mystery_tool, multiply_tool],
    user_msg="5 ve 7 羹zerinde gizemli fonksiyonu 癟al覺t覺r覺rsam ne olur?",
)
```

```python
print(str(response))
```

```python
response = llm.predict_and_call(
    [mystery_tool, multiply_tool],
    user_msg=(
        """Aa覺daki say覺 癟iftleri 羹zerinde gizemli fonksiyonu 癟al覺t覺r覺rsam ne olur? Her sat覺r i癟in ayr覺 bir sonu癟 oluturun:
- 1 ve 2
- 8 and 4
- 100 ve 20

NOT: Yukar覺daki t羹m 癟iftler i癟in gizemli fonksiyonu ayn覺 anda 癟al覺t覺rman覺z gerekiyor \
"""
    ),
    allow_parallel_tool_calls=True,
)
```

```python
print(str(response))
```

```python
for s in response.sources:
    print(f"Ad: {s.tool_name}, Girdi: {s.raw_input}, 覺kt覺: {str(s)}")
```

## Asenkron (Async)

```python
from llama_index.llms.bedrock_converse import BedrockConverse

llm = BedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    aws_access_key_id="Kullan覺lacak AWS Eriim Anahtar Kimlii",
    aws_secret_access_key="Kullan覺lacak AWS Gizli Eriim Anahtar覺",
    aws_session_token="Kullan覺lacak AWS Oturum Belirteci",
    region_name="Kullan覺lacak AWS B繹lgesi, 繹rn. us-east-1",
)
resp = await llm.acomplete("Paul Graham bir ")
```

```python
print(resp)
```
