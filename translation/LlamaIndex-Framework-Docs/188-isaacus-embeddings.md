# Isaacus Embedding'leri

`llama-index-embeddings-isaacus` paketi, Isaacus'un hukuki yapay zeka embedding modelleriyle uygulamalar oluturmak i癟in LlamaIndex entegrasyonlar覺n覺 i癟erir. Bu entegrasyon, [Massive Legal Embedding Benchmark (MLEB)](https://isaacus.com/blog/introducing-mleb) 羹zerindeki d羹nyan覺n en isabetli hukuki embedding modeli olan **Kanon 2 Embedder**'a kolayca balanman覺za ve kullanman覺za olanak tan覺r.

Isaacus embedding'leri g繹reve 繹zel optimizasyonu destekler:
- `task="retrieval/query"`: Arama sorgular覺 i癟in embedding'leri optimize et
- `task="retrieval/document"`: 襤ndekslenecek d繹k羹manlar i癟in embedding'leri optimize et

Bu not defterinde, hukuki d繹k羹man eriimi i癟in Isaacus Embedding'lerinin kullan覺m覺n覺 g繹stereceiz.

## Kurulum

Gerekli entegrasyonlar覺 kurun.

Bu not defterini Colab'da a癟覺yorsan覺z, muhtemelen LlamaIndex'i  kurman覺z gerekecektir.

```python
%pip install llama-index-embeddings-isaacus
%pip install llama-index-llms-openai
```

```python
%pip install llama-index
```

## Kurulum (Setup)

### Isaacus API anahtar覺n覺z覺 al覺n

1. [Isaacus Platformunda](https://platform.isaacus.com/accounts/signup/) hesap oluturun
2. [cretsiz kredilerinizi](https://docs.isaacus.com/pricing/credits) talep etmek i癟in bir [繹deme y繹ntemi](https://platform.isaacus.com/billing/) ekleyin
3. Bir [API anahtar覺](https://platform.isaacus.com/users/api-keys/) oluturun

```python
import os

# Isaacus API anahtar覺n覺z覺 ayarlay覺n
isaacus_api_key = "ISAACUS_API_ANAHTARINIZ"
os.environ["ISAACUS_API_KEY"] = isaacus_api_key
```

## Temel Kullan覺m

### Tek Bir Embedding Al覺n

```python
from llama_index.embeddings.isaacus import IsaacusEmbedding

# Isaacus Embedding modelini balat覺n
embed_model = IsaacusEmbedding(
    api_key=isaacus_api_key,
    model="kanon-2-embedder",
)

# Tek bir embedding al
embedding = embed_model.get_text_embedding(
    "Bu s繹zleme Delaware yasalar覺na tabi olacakt覺r."
)

print(f"Embedding boyutu: {len(embedding)}")
print(f"襤lk 5 deer: {embedding[:5]}")
```

### Toplu (Batch) Embedding'leri Al覺n

```python
# Birden fazla hukuki metin i癟in embedding al
legal_texts = [
    "Taraflar balay覺c覺 tahkimi kabul ederler.",
    "Gizli bilgiler ifa edilmeyecektir.",
    "Bu s繹zleme 30 g羹n 繹nceden bildirimde bulunarak feshedilebilir.",
]

embeddings = embed_model.get_text_embedding_batch(legal_texts)

print(f"Embedding say覺s覺: {len(embeddings)}")
print(f"Her bir embedding {len(embeddings[0])} boyuta sahiptir")
```

## G繹reve zel (Task-Specific) Embedding'ler

Isaacus embedding'leri optimal performans i癟in farkl覺 g繹revleri destekler:
- **`retrieval/document`**: 襤ndekslenecek d繹k羹manlar i癟in
- **`retrieval/query`**: Arama sorgular覺 i癟in

Uygun g繹revin kullan覺lmas覺 eriim isabetini art覺r覺r.

```python
# D繹k羹manlar i癟in (indeksleme yaparken kullan覺n)
doc_embed_model = IsaacusEmbedding(
    api_key=isaacus_api_key,
    task="retrieval/document",
)

doc_embedding = doc_embed_model.get_text_embedding(
    "irket bu s繹zlemeyi feshetme hakk覺na sahiptir."
)

print(f"D繹k羹man embedding boyutu: {len(doc_embedding)}")
```

```python
# Sorgular i癟in (get_query_embedding taraf覺ndan otomatik olarak kullan覺l覺r)
query_embedding = embed_model.get_query_embedding(
    "Fesih koullar覺 nelerdir?"
)

print(f"Sorgu embedding boyutu: {len(query_embedding)}")
```

## Boyut Azaltma (Dimensionality Reduction)

Daha h覺zl覺 arama ve daha d羹羹k depolama maliyetleri i癟in embedding boyutunu azaltabilirsiniz:

```python
# Azalt覺lm覺 boyutlar覺 kullan (varsay覺lan 1792'dir)
embed_model_512 = IsaacusEmbedding(
    api_key=isaacus_api_key,
    dimensions=512,
)

embedding_512 = embed_model_512.get_text_embedding("Hukuki metin 繹rnei")

print(f"Azalt覺lm覺 embedding boyutu: {len(embedding_512)}")
```

## Hukuki D繹k羹manlarla Tam RAG rnei

imdi bir hukuki d繹k羹man (Uber'in 10-K SEC raporu) ile Isaacus embedding'lerini kullanarak tam bir RAG boru hatt覺 olutural覺m.

```python
import logging
import sys

logging.basicConfig(stream=sys.stdout, level=logging.INFO)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.llms.openai import OpenAI
from llama_index.core.response.notebook_utils import display_source_node
from IPython.display import Markdown, display
```

### Hukuki D繹k羹man Verilerini 襤ndir

Hukuki ve d羹zenleyici bilgiler i癟eren Uber'in 10-K SEC raporunu kullanaca覺z; bu, Kanon 2'nin hukuk alan覺 uzmanl覺覺n覺 g繹stermek i癟in m羹kemmeldir.

```python
!mkdir -p 'data/10k/'
!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf' -O 'data/10k/uber_2021.pdf'
```

### Hukuki D繹k羹man覺 Y羹kle

```python
documents = SimpleDirectoryReader("./data/10k/").load_data()
print(f"{len(documents)} d繹k羹man y羹klendi")
```

### D繹k羹man G繹revi ile 襤ndeks 襤na Et

D繹k羹man depolamas覺 i癟in embedding'leri optimize etmek amac覺yla indeksi olutururken `task="retrieval/document"` parametresini kullan覺yoruz.

```python
# D繹k羹manlar i癟in embedding modelini balat覺n
embed_model = IsaacusEmbedding(
    api_key=isaacus_api_key,
    model="kanon-2-embedder",
    task="retrieval/document",
)

# 襤ndeksi ina et
index = VectorStoreIndex.from_documents(
    documents=documents,
    embed_model=embed_model,
)
```

### Hukuki Sorularla Sorgulama

imdi indeksi hukuki nitelikteki sorularla sorgulayaca覺z. `get_query_embedding` y繹nteminin optimal sorgu performans覺 i癟in otomatik olarak `task="retrieval/query"` kulland覺覺n覺 unutmay覺n.

```python
# Bir eriici (retriever) oluturun
retriever = index.as_retriever(similarity_top_k=3)

# Risk fakt繹rleri hakk覺nda sorgu
retrieved_nodes = retriever.retrieve(
    "D繹k羹manda belirtilen ana risk fakt繹rleri nelerdir?"
)

print(f"{len(retrieved_nodes)} d羹羹m (node) getirildi\n")

for i, node in enumerate(retrieved_nodes):
    print(f"\n--- D羹羹m {i+1} (Skor: {node.score:.4f}) ---")
    display_source_node(node, source_length=500)
```

### Yasal 襤lemler Hakk覺nda Sorgulama

```python
# Yasal ilemler hakk覺nda sorgu
retrieved_nodes = retriever.retrieve(
    "irket hangi yasal ilemler veya davalarla ilgileniyor?"
)

print(f"{len(retrieved_nodes)} d羹羹m (node) getirildi\n")

for i, node in enumerate(retrieved_nodes):
    print(f"\n--- D羹羹m {i+1} (Skor: {node.score:.4f}) ---")
    display_source_node(node, source_length=500)
```

### LLM ile Sorgu Motoru 襤na Edin

Eksiksiz bir soru-cevap sistemi i癟in Isaacus embeddinglerini bir LLM ile birletirin:

```python
import os

# OpenAI API anahtar覺n覺z覺 ayarlay覺n
openai_api_key = "OPENAI_API_ANAHTARINIZ"
os.environ["OPENAI_API_KEY"] = openai_api_key
```

```python
# LLM'i kurun
llm = OpenAI(model="gpt-4o-mini", temperature=0)

# Sorgu motorunu oluturun
query_engine = index.as_query_engine(
    llm=llm,
    similarity_top_k=5,
)

# Hukuki bir soru sorun
response = query_engine.query(
    "irketin ana d羹zenleyici ve hukuki riskleri nelerdir?"
)

display(Markdown(f"**Cevap:** {response}"))
```

### Baka Bir Hukuki Sorgu

```python
response = query_engine.query(
    "irket hangi fikri m羹lkiyet haklar覺na g羹veniyor?"
)

display(Markdown(f"**Cevap:** {response}"))
```

## Asenkron (Async) Kullan覺m

Isaacus embedding'leri, asenkron uygulamalarda daha iyi performans i癟in asenkron ilemleri de destekler:

```python
import asyncio


async def get_embeddings_async():
    embed_model = IsaacusEmbedding(
        api_key=isaacus_api_key,
    )

    # Asenkron tekli embedding al
    embedding = await embed_model.aget_text_embedding(
        "Asenkron hukuki d繹k羹man metni"
    )

    # Asenkron toplu embedding al
    embeddings = await embed_model.aget_text_embedding_batch(
        ["Metin 1", "Metin 2", "Metin 3"]
    )

    return embedding, embeddings


# Asenkron fonksiyonu 癟al覺t覺r
embedding, embeddings = await get_embeddings_async()

print(f"Asenkron tekli embedding boyutu: {len(embedding)}")
print(
    f"Asenkron toplu ilem: her biri {len(embeddings[0])} boyutta {len(embeddings)} adet embedding"
)
```

## zet

Bu not defterinde unlar覺 g繹sterdik:

1. **Temel kullan覺m** - Tekli ve toplu embedding alma
2. **G繹reve 繹zel optimizasyon** - 襤ndeksleme i癟in `retrieval/document` ve arama i癟in `retrieval/query` kullan覺m覺
3. **Boyut azaltma** - Verimlilik i癟in embedding boyutunu k羹癟羹ltme
4. **Hukuki RAG boru hatt覺** - Hukuki d繹k羹manlarla (Uber 10-K) eksiksiz bir eriim sistemi ina etme
5. **Asenkron ilemler** - Daha iyi performans i癟in asenkron y繹ntemlerin kullan覺m覺

Kanon 2 Embedder, hukuki d繹k羹man anlama ve getirme konular覺nda 羹st羹nd羹r; bu da onu legal tech uygulamalar覺, uyumluluk (compliance) ara癟lar覺, s繹zleme analizi ve daha fazlas覺 i癟in ideal k覺lar.

## Ek Kaynaklar

- [Isaacus D繹k羹mantasyonu](https://docs.isaacus.com)
- [Kanon 2 Embedder Duyurusu](https://isaacus.com/blog/introducing-kanon-2-embedder)
- [Massive Legal Embedding Benchmark (MLEB)](https://isaacus.com/blog/introducing-mleb)
- [Isaacus Platformu](https://platform.isaacus.com)