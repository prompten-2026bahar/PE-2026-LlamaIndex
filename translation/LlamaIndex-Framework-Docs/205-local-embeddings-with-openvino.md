# OpenVINO ile Yerel GÃ¶mmeler (Local Embeddings)

[OpenVINOâ„¢](https://github.com/openvinotoolkit/openvino), yapay zeka Ã§Ä±karÄ±mÄ±nÄ± (inference) optimize etmek ve daÄŸÄ±tmak iÃ§in kullanÄ±lan aÃ§Ä±k kaynaklÄ± bir araÃ§ setidir. OpenVINOâ„¢ Runtime, x86 ve ARM CPU'lar ile Intel GPU'lar dahil olmak Ã¼zere Ã§eÅŸitli donanÄ±m [aygÄ±tlarÄ±nÄ±](https://github.com/openvinotoolkit/openvino?tab=readme-ov-file#supported-hardware-matrix) destekler. BilgisayarlÄ± GÃ¶rÃ¼, Otomatik KonuÅŸma TanÄ±ma, DoÄŸal Dil Ä°ÅŸleme ve diÄŸer yaygÄ±n gÃ¶revlerde derin Ã¶ÄŸrenme performansÄ±nÄ± artÄ±rmaya yardÄ±mcÄ± olabilir.

Hugging Face gÃ¶mme (embedding) modeli OpenVINO tarafÄ±ndan `OpenVINOEmbedding` veya `OpenVINOGENAIEmbedding` sÄ±nÄ±fÄ± aracÄ±lÄ±ÄŸÄ±yla desteklenebilir; OpenClip modeli ise `OpenVINOClipEmbedding` sÄ±nÄ±fÄ± aracÄ±lÄ±ÄŸÄ±yla desteklenebilir.

EÄŸer bu not defterini colab Ã¼zerinde aÃ§Ä±yorsanÄ±z, muhtemelen LlamaIndex'i ğŸ¦™ kurmanÄ±z gerekecektir.

```python
%pip install llama-index-embeddings-openvino
```

```python
!pip install llama-index
```

## Model DÄ±ÅŸa AktarÄ±cÄ± (Model Exporter)

`create_and_save_openvino_model` fonksiyonu ile modelinizi OpenVINO IR formatÄ±na dÄ±ÅŸa aktarmanÄ±z ve modeli yerel klasÃ¶rden yÃ¼klemeniz mÃ¼mkÃ¼ndÃ¼r.

```python
from llama_index.embeddings.huggingface_openvino import OpenVINOEmbedding

OpenVINOEmbedding.create_and_save_openvino_model(
    "BAAI/bge-small-en-v1.5", "./bge_ov"
)
```

    /home2/ethan/intel/llama_index/llama_test/lib/python3.10/site-packages/openvino/runtime/__init__.py:10: DeprecationWarning: `openvino.runtime` modÃ¼lÃ¼ kullanÄ±mdan kaldÄ±rÄ±lmÄ±ÅŸtÄ±r ve 2026.0 sÃ¼rÃ¼mÃ¼nde kaldÄ±rÄ±lacaktÄ±r. LÃ¼tfen `openvino.runtime` yerine `openvino` kullanÄ±n.
      warnings.warn(

    OpenVINO modeli ./bge_ov dizinine kaydedildi. Åununla kullanÄ±n: `embed_model = OpenVINOEmbedding(model_id_or_path='./bge_ov')`.

## Model YÃ¼kleme (Model Loading)

EÄŸer bir Intel GPU'nuz varsa, Ã§Ä±karÄ±mÄ± orada Ã§alÄ±ÅŸtÄ±rmak iÃ§in `device="gpu"` belirtebilirsiniz.

```python
ov_embed_model = OpenVINOEmbedding(model_id_or_path="./bge_ov", device="cpu")
```

```python
embeddings = ov_embed_model.get_text_embedding("Merhaba DÃ¼nya!")
print(len(embeddings))
print(embeddings[:5])
```

    384
    [-0.0030246784444898367, -0.012189766392111778, 0.04163273051381111, -0.037758368998765945, 0.02439723163843155]

## OpenVINO GenAI ile Model YÃ¼kleme

Ã‡alÄ±ÅŸma zamanÄ±nda PyTorch baÄŸÄ±mlÄ±lÄ±klarÄ±ndan kaÃ§Ä±nmak iÃ§in yerel gÃ¶mme modelinizi `OpenVINOGENAIEmbedding` sÄ±nÄ±fÄ± ile yÃ¼kleyebilirsiniz.

```python
%pip install llama-index-embeddings-openvino-genai
```

```python
from llama_index.embeddings.openvino_genai import OpenVINOGENAIEmbedding

ov_embed_model = OpenVINOGENAIEmbedding(model_path="./bge_ov", device="CPU")
```

    /home2/ethan/intel/llama_index/llama_test/lib/python3.10/site-packages/openvino/runtime/__init__.py:10: DeprecationWarning: `openvino.runtime` modÃ¼lÃ¼ kullanÄ±mdan kaldÄ±rÄ±lmÄ±ÅŸtÄ±r ve 2026.0 sÃ¼rÃ¼mÃ¼nde kaldÄ±rÄ±lacaktÄ±r. LÃ¼tfen `openvino.runtime` yerine `openvino` kullanÄ±n.
      warnings.warn(

```python
embeddings = ov_embed_model.get_text_embedding("Merhaba DÃ¼nya!")
print(len(embeddings))
print(embeddings[:5])
```

    384
    [-0.0030246784444898367, -0.012189766392111778, 0.04163273051381111, -0.037758368998765945, 0.02439723163843155]

## OpenClip Model DÄ±ÅŸa AktarÄ±cÄ±

`OpenVINOClipEmbedding` sÄ±nÄ±fÄ±, OpenVINO Ã§alÄ±ÅŸma zamanÄ± ile open_clip modellerini dÄ±ÅŸa aktarmayÄ± ve yÃ¼klemeyi destekleyebilir.

```python
%pip install open_clip_torch
```

```python
from llama_index.embeddings.huggingface_openvino import (
    OpenVINOClipEmbedding,
)

OpenVINOClipEmbedding.create_and_save_openvino_model(
    "laion/CLIP-ViT-B-32-laion2B-s34B-b79K",
    "ViT-B-32-ov",
)
```

## Ã‡ok Modlu (MultiModal) Model YÃ¼kleme

EÄŸer bir Intel GPU'nuz varsa, Ã§Ä±karÄ±mÄ± orada Ã§alÄ±ÅŸtÄ±rmak iÃ§in `device="GPU"` belirtebilirsiniz.

```python
ov_clip_model = OpenVINOClipEmbedding(
    model_id_or_path="./ViT-B-32-ov", device="CPU"
)
```

## OpenVINO ile gÃ¶rÃ¼ntÃ¼leri ve sorgularÄ± gÃ¶mme

```python
from PIL import Image
import requests
from numpy import dot
from numpy.linalg import norm

image_url = "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcStMP8S3VbNCqOQd7QQQcbvC_FLa1HlftCiJw&s"
im = Image.open(requests.get(image_url, stream=True).raw)
print("GÃ¶rÃ¼ntÃ¼:")
display(im)

im.save("logo.jpg")
image_embeddings = ov_clip_model.get_image_embedding("logo.jpg")
print("GÃ¶rÃ¼ntÃ¼ boyutu:", len(image_embeddings))
print("GÃ¶rÃ¼ntÃ¼ gÃ¶mmesi:", image_embeddings[:5])

text_embeddings = ov_clip_model.get_text_embedding(
    "Koyu arka plan Ã¼zerinde pembe mavi bir larkanÄ±n (llama) logosu"
)
print("Metin boyutu:", len(text_embeddings))
print("Metin gÃ¶mmesi:", text_embeddings[:5])

cos_sim = dot(image_embeddings, text_embeddings) / (
    norm(image_embeddings) * norm(text_embeddings)
)
print("KosinÃ¼s benzerliÄŸi:", cos_sim)
```

    GÃ¶rÃ¼ntÃ¼:

![png](output_19_1.png)

    GÃ¶rÃ¼ntÃ¼ boyutu: 512
    GÃ¶rÃ¼ntÃ¼ gÃ¶mmesi: [-0.03019799292087555, -0.09727513045072556, -0.6659489274024963, -0.025658488273620605, 0.05379948765039444]
    Metin boyutu: 512
    Metin gÃ¶mmesi: [-0.15816599130630493, -0.25564345717430115, 0.22376027703285217, -0.34983670711517334, 0.31968361139297485]
    KosinÃ¼s benzerliÄŸi: 0.27307014923203976

Daha fazla bilgi iÃ§in ÅŸuralara bakabilirsiniz:

* [OpenVINO LLM kÄ±lavuzu](https://docs.openvino.ai/2024/learn-openvino/llm_inference_guide.html).

* [OpenVINO DokÃ¼mantasyonu](https://docs.openvino.ai/2024/home.html).

* [OpenVINO BaÅŸlangÄ±Ã§ KÄ±lavuzu](https://www.intel.com/content/www/us/en/content-details/819067/openvino-get-started-guide.html).

* [LlamaIndex ile RAG Ã¶rneÄŸi](https://github.com/openvinotoolkit/openvino_notebooks/tree/latest/notebooks/llm-rag-llamaindex).
