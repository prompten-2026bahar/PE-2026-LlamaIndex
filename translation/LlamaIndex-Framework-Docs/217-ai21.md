# AI21

Bu not defteri, AI21'in temel modellerinin (foundation models) LlamaIndex'te nas覺l kullan覺laca覺n覺 g繹sterir. Varsay覺lan model `jamba-1.5-mini`'dir.
Desteklenen dier modeller `jamba-1.5-large` ve `jamba-instruct`'t覺r. Eer daha eski Jurassic modellerini kullanmak isterseniz, `j2-mid` veya `j2-ultra` model ad覺n覺 belirtin.

## Temel Kullan覺m

Eer bu not defterini colab 羹zerinden a癟覺yorsan覺z, muhtemelen LlamaIndex'i  kurman覺z gerekecektir.

```python
%pip install llama-index-llms-ai21
```

```python
!pip install llama-index
```

## AI21 API Anahtar覺n覺 Ayarlama

Bir `AI21` 繹rnei olutururken, API anahtar覺n覺 bir parametre olarak ge癟irebilirsiniz. Eer parametre olarak salanmazsa, varsay覺lan olarak `AI21_API_KEY` ortam deikeninin deerini kullan覺r.

```python
import os
from llama_index.llms.ai21 import AI21

# UNUNLA
api_key = "<API ANAHTARINIZ>"
os.environ["AI21_API_KEY"] = api_key

llm = AI21()

# VEYA UNUNLA
llm = AI21(api_key=api_key)
```

#### Mesaj listesiyle `chat` 癟ar覺s覺

Mesajlar, en eskiden en yeniye doru, bir `user` rol羹 mesaj覺yla balamal覺 ve `user` ile `assistant` mesajlar覺 aras覺nda s覺rayla deimelidir.

```python
from llama_index.core.llms import ChatMessage
from llama_index.llms.ai21 import AI21

messages = [
    ChatMessage(role="user", content="merhaba"),
    ChatMessage(
        role="assistant", content="Arrrr, ahbap! Bug羹n sana nas覺l yard覺m edebilirim?"
    ),
    ChatMessage(role="user", content="Ad覺n ne?"),
]

# Asistan覺n sesini ve tonunu belirtmek i癟in `preamble_override` kullan覺n.
resp = AI21(api_key=api_key).chat(
    messages, preamble_override="Sen renkli bir kiilie sahip bir korsans覺n"
)
```

```python
print(resp)
```

    assistant: Arrrr, bana Kaptan Jamba diyebilirsin! Ben dost canl覺s覺 bir korsan yapay zekay覺m, sahip olabilecein her t羹rl羹 soruda sana yard覺m etmek i癟in buraday覺m.

#### Bir istem (prompt) ile `complete` 癟ar覺s覺

```python
from llama_index.llms.ai21 import AI21

api_key = "Api anahtar覺n覺z"
resp = AI21(api_key=api_key).complete("Paul Graham ")
```

```python
print(resp)
```

    Paul Graham bir bilgisayar bilimcisi, giriimci ve yazard覺r. En 癟ok, Dropbox, Airbnb ve Reddit dahil olmak 羹zere 2.000'den fazla giriimi finanse eden bir risk sermayesi irketi olan Y Combinator'覺n kurucu orta覺 olarak bilinir. Graham ayr覺ca paulgraham.com adresindeki web sitesinde yay覺nlad覺覺 teknoloji, giriimler ve programlama dilleri hakk覺ndaki denemeleriyle de tan覺n覺r. 襤nsanlar覺n hayatlar覺n覺 iyiletirmek i癟in teknolojinin kullan覺lmas覺n覺n g羹癟l羹 bir savunucusudur ve giriimciliin ve inovasyonun 繹nemi hakk覺nda kapsaml覺 yaz覺lar yazm覺t覺r.

## Asenkron Metotlar覺 a覺rma

```python
from llama_index.core.llms import ChatMessage
from llama_index.llms.ai21 import AI21

prompt = "Hayat覺n anlam覺 nedir?"

messages = [
    ChatMessage(role="user", content=prompt),
]

chat_resp = await AI21(api_key=api_key).achat(messages)

complete_resp = await AI21(api_key=api_key).acomplete(prompt)
```

## Model Davran覺覺n覺 Ayarlama

Modelin davran覺覺n覺 ayarlamak i癟in modele iletilen parametreleri yap覺land覺r覺n. rnein, daha d羹羹k bir `temperature` (s覺cakl覺k) deeri ayarlamak, 癟ar覺lar aras覺ndaki varyasyonun daha az olmas覺na neden olur. `temperature=0` ayarlan覺rsa, her seferinde ayn覺 soruya ayn覺 cevap 羹retilir.

```python
from llama_index.llms.ai21 import AI21

llm = AI21(
    model="jamba-1.5-mini", api_key=api_key, max_tokens=100, temperature=0.5
)
```

```python
resp = llm.complete("Paul Graham ")
```

```python
print(resp)
```

    Paul Graham, Amerikal覺 bir bilgisayar bilimcisi, giriimci ve yazard覺r. En 癟ok bilgisayar programlama dilleri alan覺ndaki 癟al覺malar覺, 繹zellikle Arc programlama dilinin gelitirilmesiyle tan覺n覺r. Ayr覺ca, bir癟ok baar覺l覺 teknoloji giriiminin balat覺lmas覺na yard覺mc覺 olan etkili giriim h覺zland覺r覺c覺s覺 Y Combinator'覺n kurucu orta覺d覺r.

## Ak覺 (Streaming)

`stream_chat` metodunu kullanarak 羹retilen yan覺tlar覺 her mesajda birer belirte癟 (token) olacak ekilde ak覺 halinde al覺n.

```python
from llama_index.llms.ai21 import AI21
from llama_index.core.llms import ChatMessage

llm = AI21(api_key=api_key, model="jamba-1.5-mini")
messages = [
    ChatMessage(
        role="system", content="Sen renkli bir kiilie sahip bir korsans覺n"
    ),
    ChatMessage(role="user", content="Bana bir hikaye anlat"),
]
resp = llm.stream_chat(messages)
```

```python
for r in resp:
    print(r.delta, end="")
```

    Bir zamanlar, uzak bir diyarda, Kaptan Jack ad覺nda cesur ve macerac覺 bir korsan varm覺. Renkli bir kiilii varm覺 ve k覺vrak zekas覺 ve kurnazl覺覺yla tan覺n覺rm覺.
    
    Bir g羹n Kaptan Jack, hazine aramak i癟in sad覺k gemisi Siyah 襤nci ile denize a癟覺lm覺. O ve m羹rettebat覺 tehlikeli sularda yelken a癟m覺 ve iddetli f覺rt覺nalarla savam覺lar ama asla pes etmemiler.
    
    Denizde ge癟en uzun g羹nlerin ard覺ndan, nihayet hazinenin g繹m羹l羹 olduu s繹ylenen aday覺 bulmular. Gemilerini demirlemiler ve sad覺k k覺l覺癟lar覺 ve tabancalar覺yla yaya olarak yola koyulmular.
    
    S覺k orman覺n derinliklerine doru ilerlerken, zehirli y覺lanlardan dev 繹r羹mceklere kadar her t羹rl羹 tehlikeli yarat覺kla kar覺lam覺lar. Ama Kaptan Jack ve m羹rettebat覺 korkmam覺lar. Hazineye ulamaya kararl覺 bir ekilde yollar覺n覺 a癟m覺lar.
    
    Sonunda, sanki sonsuzluk gibi gelen bir s羹renin ard覺ndan hazinenin g繹m羹l羹 olmas覺 gereken yere varm覺lar. Topra覺 derinlemesine kazm覺lar, kalpleri heyecanla 癟arp覺yormu. Ve sonunda alt覺na ulam覺lar!
    
    Hazineyi bulmulard覺! Kaptan Jack ve m羹rettebat覺 sevin癟ten havalara u癟mu. Ta覺yabildikleri kadar alt覺n ve m羹cevheri toplay覺p eve d繹nmek 羹zere yelken a癟m覺lar.
    
    Ana limanlar覺na d繹nerken Kaptan Jack, m羹rettebat覺na maceralar覺n覺 ve at覺klar覺 tehlikeleri anlatm覺. anslar覺na g羹lm羹ler, ark覺 s繹ylemiler ve i癟miler.
    
    Nihayet eve vard覺klar覺nda Kaptan Jack ve m羹rettebat覺 kahramanlar gibi kar覺lanm覺. Hazineyi bulmak i癟in her eyi riske atm覺lar ve zaferle d繹nm羹lerdi. Ve Kaptan Jack, renkli kiiliiyle hepsinin en 癟ok kutlanan覺 olmu.

## Belirte癟 Oluturucu (Tokenizer)

Farkl覺 modeller farkl覺 belirte癟 oluturucular kullan覺r.

```python
from llama_index.llms.ai21 import AI21

llm = AI21(api_key=api_key, model="jamba-1.5-mini")

tokenizer = llm.tokenizer

tokens = tokenizer.encode("Merhaba llama-index!")

decoded = tokenizer.decode(tokens)

print(decoded)
```

## Ara癟 a覺rma (Tool Calling)

```python
from llama_index.core.agent import FunctionAgent
from llama_index.llms.ai21 import AI21
from llama_index.core.tools import FunctionTool


def multiply(a: int, b: int) -> int:
    """襤ki tam say覺y覺 癟arpar ve sonu癟 tam say覺s覺n覺 d繹nd羹r羹r"""
    return a * b


def subtract(a: int, b: int) -> int:
    """襤ki tam say覺y覺 癟覺kar覺r ve sonu癟 tam say覺s覺n覺 d繹nd羹r羹r"""
    return a - b


def divide(a: int, b: int) -> float:
    """襤ki tam say覺y覺 b繹ler ve sonu癟 float deerini d繹nd羹r羹r"""
    return a / b


def add(a: int, b: int) -> int:
    """襤ki tam say覺y覺 toplar ve sonu癟 tam say覺s覺n覺 d繹nd羹r羹r"""
    return a + b


multiply_tool = FunctionTool.from_defaults(fn=multiply)
add_tool = FunctionTool.from_defaults(fn=add)
subtract_tool = FunctionTool.from_defaults(fn=subtract)
divide_tool = FunctionTool.from_defaults(fn=divide)

llm = AI21(model="jamba-1.5-mini", api_key=api_key)

agent = FunctionAgent(
    tools=[multiply_tool, add_tool, subtract_tool, divide_tool],
    llm=llm,
)

response = await agent.run(
    "Arkada覺m Moses'覺n 10 elmas覺 vard覺. Sabah 5 elma yedi. Sonra 25 elmal覺 bir kutu buldu. T羹m elmalar覺n覺 5 arkada覺 aras覺nda paylat覺rd覺. Her bir arkada覺na ka癟 elma d羹t羹?"
)
```
