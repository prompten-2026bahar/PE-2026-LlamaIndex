# Google GenAI Embedding'leri

Google'覺n `google-genai` paketini kullanan LlamaIndex, hem Gemini hem de Vertex AI API'lerinden gelen Google GenAI modellerini kullanarak metinleri g繹mmenize (embed) olanak tan覺yan bir `GoogleGenAIEmbedding` s覺n覺f覺 sunar.

Bu not defterini Colab'da a癟覺yorsan覺z, muhtemelen LlamaIndex'i  kurman覺z gerekecektir.

```python
%pip install llama-index-embeddings-google-genai
```

```python
import os

os.environ["GOOGLE_API_KEY"] = "..."
```

## Kurulum

`GoogleGenAIEmbedding`, `google-genai` paketi i癟in bir sarmalay覺c覺d覺r (wrapper); bu da hem Gemini hem de Vertex AI API'lerini kutudan 癟覺kt覺覺 gibi destekledii anlam覺na gelir.

`api_key` deerini dorudan ge癟irebilir veya Vertex AI API'sini kullanmak i癟in bir `vertexai_config` ge癟irebilirsiniz.

Dier se癟enekler aras覺nda `embed_batch_size`, `model_name` ve `embedding_config` bulunur.

Varsay覺lan model `text-embedding-004`'t羹r.

```python
from llama_index.embeddings.google_genai import GoogleGenAIEmbedding
from google.genai.types import EmbedContentConfig

embed_model = GoogleGenAIEmbedding(
    model_name="text-embedding-004",
    embed_batch_size=100,
    # api anahtar覺n覺 dorudan ge癟irebilirsiniz
    # api_key="...",
    # veya bir vertexai_config ge癟irebilirsiniz
    # vertexai_config={
    #     "project": "...",
    #     "location": "...",
    # }
    # bir embedding_config de ge癟irebilirsiniz
    # embedding_config=EmbedContentConfig(...)
)
```

## Kullan覺m

### Senkronize (Sync)

```python
embeddings = embed_model.get_text_embedding("Google Gemini Embedding'leri.")
print(embeddings[:5])
print(f"Embedding boyutu: {len(embeddings)}")
```

    [0.031099992, 0.02192731, -0.06523498, 0.016788177, 0.0392835]
    Dimension of embeddings: 768

```python
embeddings = embed_model.get_query_embedding("Google Gemini Embedding'lerini Sorgula.")
print(embeddings[:5])
print(f"Embedding boyutu: {len(embeddings)}")
```

    [0.022199392, 0.03671178, -0.06874573, 0.02195774, 0.05475164]
    Dimension of embeddings: 768

```python
embeddings = embed_model.get_text_embedding_batch(
    [
        "Google Gemini Embedding'leri.",
        "Google harikad覺r.",
        "Llamaindex harikad覺r.",
    ]
)
print(f"{len(embeddings)} adet embedding al覺nd覺")
print(f"Embedding boyutu: {len(embeddings[0])}")
```

    Got 3 embeddings
    Dimension of embeddings: 768

### Asenkronize (Async)

```python
embeddings = await embed_model.aget_text_embedding("Google Gemini Embedding'leri.")
print(embeddings[:5])
print(f"Embedding boyutu: {len(embeddings)}")
```

    [0.031099992, 0.02192731, -0.06523498, 0.016788177, 0.0392835]
    Dimension of embeddings: 768

```python
embeddings = await embed_model.aget_query_embedding(
    "Google Gemini Embedding'lerini Sorgula."
)
print(embeddings[:5])
print(f"Embedding boyutu: {len(embeddings)}")
```

    [0.022199392, 0.03671178, -0.06874573, 0.02195774, 0.05475164]
    Dimension of embeddings: 768

```python
embeddings = await embed_model.aget_text_embedding_batch(
    [
        "Google Gemini Embedding'leri.",
        "Google harikad覺r.",
        "Llamaindex harikad覺r.",
    ]
)
print(f"{len(embeddings)} adet embedding al覺nd覺")
print(f"Embedding boyutu: {len(embeddings[0])}")
```

    Got 3 embeddings
    Dimension of embeddings: 768