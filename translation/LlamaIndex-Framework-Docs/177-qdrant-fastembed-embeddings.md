# Qdrant FastEmbed Embedding'leri

LlamaIndex, embedding oluÅŸturma iÃ§in [FastEmbed](https://qdrant.github.io/fastembed/)'i destekler.

Bu not defterini Colab'da aÃ§Ä±yorsanÄ±z, muhtemelen LlamaIndex'i ğŸ¦™ kurmanÄ±z gerekecektir.

```python
%pip install llama-index-embeddings-fastembed
```

```python
%pip install llama-index
```

Bu saÄŸlayÄ±cÄ±yÄ± kullanmak iÃ§in `fastembed` paketinin kurulu olmasÄ± gerekir.

```python
%pip install fastembed
```

Desteklenen modellerin listesi [burada](https://qdrant.github.io/fastembed/examples/Supported_Models/) bulunabilir.

```python
from llama_index.embeddings.fastembed import FastEmbedEmbedding

embed_model = FastEmbedEmbedding(model_name="BAAI/bge-small-en-v1.5")
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76.7M/76.7M [00:18<00:00, 4.23MiB/s]

```python
embeddings = embed_model.get_text_embedding("GÃ¶mÃ¼lecek (embed edilecek) bazÄ± metinler.")
print(len(embeddings))
print(embeddings[:5])
```

    384
    [-0.04166769981384277, 0.0018720313673838973, 0.02632238157093525, -0.036030545830726624, -0.014812108129262924]