# Aleph Alpha Embedding'leri

Bu not defterini Colab'da a癟覺yorsan覺z, muhtemelen LlamaIndex'i  kurman覺z gerekecektir.

```python
%pip install llama-index-embeddings-alephalpha
```

```python
!pip install llama-index
```

```python
# AA belirtecinizle (AA token) balat覺n
import os

os.environ["AA_TOKEN"] = "your_token_here"
```

#### `luminous-base` embedding'leri ile.

-   representation="Document" (Belge): Bunu vekt繹r veritaban覺n覺zda saklamak istediiniz metinler (belgeler) i癟in kullan覺n.
-   representation="Query" (Sorgu): Bunu vekt繹r veritaban覺n覺zdaki en alakal覺 d繹k羹manlar覺 bulmak amac覺yla kullan覺lan arama sorgular覺 i癟in kullan覺n.
-   representation="Symmetric" (Simetrik): Bunu k羹meleme, s覺n覺fland覺rma, anomali tespiti veya g繹rselletirme g繹revleri i癟in kullan覺n.

```python
from llama_index.embeddings.alephalpha import AlephAlphaEmbedding

# Belirtecinizi 繹zelletirmek i癟in unu yap覺n
# aksi takdirde ortam deikeninizden AA_TOKEN'覺 arayacakt覺r
# embed_model = AlephAlpha(token="<aa_token>")

# representation='Query' ile
embed_model = AlephAlphaEmbedding(
    model="luminous-base",
    representation="Query",
)

embeddings = embed_model.get_text_embedding("Merhaba Aleph Alpha!")

print(len(embeddings))
print(embeddings[:5])
```

    representation_enum: SemanticRepresentation.Query

    5120
    [0.14257812, 2.59375, 0.33203125, -0.33789062, -0.94140625]

```python
# representation='Document' ile
embed_model = AlephAlphaEmbedding(
    model="luminous-base",
    representation="Document",
)

embeddings = embed_model.get_text_embedding("Merhaba Aleph Alpha!")

print(len(embeddings))
print(embeddings[:5])
```

    representation_enum: SemanticRepresentation.Document

    5120
    [0.14257812, 2.59375, 0.33203125, -0.33789062, -0.94140625]