# Anthropic

Anthropic; haiku, sonnet ve opus ailelerinden pek Ã§ok son teknoloji model sunar.

Bu modelleri LlamaIndex ile nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸrenmek iÃ§in okumaya devam edin!

EÄŸer bu not defterini colab Ã¼zerinde aÃ§Ä±yorsanÄ±z, muhtemelen LlamaIndex'i ğŸ¦™ kurmanÄ±z gerekecektir.

```python
%pip install llama-index-llms-anthropic
```

#### BelirteÃ§ OluÅŸturucuyu (Tokenizer) Ayarla

Ã–ncelikle, TikToken'dan biraz farklÄ± olan belirteÃ§ oluÅŸturucuyu ayarlamak istiyoruz. Bu, kitaplÄ±k genelinde belirteÃ§ sayÄ±mÄ±nÄ±n doÄŸru olmasÄ±nÄ± saÄŸlar.

**NOT**: Anthropic yakÄ±n zamanda belirteÃ§ sayma API'sini gÃ¼ncelledi. claude-2.1 gibi eski modeller, Anthropic python istemcisinin en yeni sÃ¼rÃ¼mlerinde belirteÃ§ sayÄ±mÄ± iÃ§in artÄ±k desteklenmemektedir.

```python
from llama_index.llms.anthropic import Anthropic
from llama_index.core import Settings

tokenizer = Anthropic().tokenizer
Settings.tokenizer = tokenizer
```

## Temel KullanÄ±m

```python
import os

os.environ["ANTHROPIC_API_KEY"] = "sk-..."
```

Bir istemle (prompt) `complete` Ã§aÄŸrÄ±sÄ± yapabilirsiniz:

```python
from llama_index.llms.anthropic import Anthropic

# API anahtarÄ±nÄ±zÄ± Ã¶zelleÅŸtirmek iÃ§in bunu yapÄ±n,
# aksi takdirde ortam deÄŸiÅŸkeninizden ANTHROPIC_API_KEY aranacaktÄ±r
# llm = Anthropic(api_key="<api_key>")
llm = Anthropic(model="claude-sonnet-4-0")

resp = llm.complete("Paul Graham kimdir?")
```

```python
print(resp)
```

    Paul Graham bir bilgisayar programcÄ±sÄ±, giriÅŸimci, risk sermayedarÄ± ve denemecidir. Ä°ÅŸte tanÄ±ndÄ±ÄŸÄ± baÅŸlÄ±ca noktalar:
    
    **Y Combinator**: 2005 yÄ±lÄ±nda Airbnb, Dropbox, Stripe ve Reddit gibi ÅŸirketlerin kurulmasÄ±na yardÄ±mcÄ± olan bu oldukÃ§a etkili giriÅŸim hÄ±zlandÄ±rÄ±cÄ±sÄ±nÄ±n kurucu ortaklarÄ±ndandÄ±r. Y Combinator, erken aÅŸamadaki giriÅŸimlere tohum yatÄ±rÄ±mÄ± ve mentÃ¶rlÃ¼k saÄŸlar.
    
    **Programlama**: Programlama topluluÄŸunda saygÄ±n bir figÃ¼rdÃ¼r, Ã¶zellikle Lisp programlama dili Ã¼zerindeki Ã§alÄ±ÅŸmalarÄ±yla ve 1990'larda ilk web tabanlÄ± uygulama olan Viaweb'i (Yahoo'ya satÄ±larak Yahoo Store olmuÅŸtur) ortaklaÅŸa oluÅŸturmasÄ±yla tanÄ±nÄ±r.
    
    **YazarlÄ±k**: Graham, paulgraham.com adresindeki web sitesinde yayÄ±nladÄ±ÄŸÄ± giriÅŸimler, teknoloji, programlama ve toplum Ã¼zerine dÃ¼ÅŸÃ¼nceli denemeleriyle tanÄ±nÄ±r. Denemeleri teknoloji Ã§evrelerinde geniÅŸ Ã§apta okunur ve bir giriÅŸimin nasÄ±l kurulacaÄŸÄ±, inovasyonun doÄŸasÄ± ve sosyal yorumlar gibi konularÄ± kapsar.
    
    **Kitaplar**: "Hackers & Painters" ve "On Lisp" dahil olmak Ã¼zere birkaÃ§ kitabÄ±n yazarÄ±dÄ±r.
    
    **Etki**: Hem Y Combinator'Ä±n etkisiyle hem de giriÅŸimcilik ve teknoloji Ã¼zerine yazÄ±larÄ±yla Silikon Vadisi'nin giriÅŸim ekosistemindeki en etkili kiÅŸilerden biri olarak kabul edilir.
    
    Graham, analitik dÃ¼ÅŸÃ¼ncesi ve iÅŸ dÃ¼nyasÄ±, teknoloji ve kÃ¼ltÃ¼r hakkÄ±ndaki aykÄ±rÄ± perspektifleriyle tanÄ±nÄ±r.

Sohbet mesajlarÄ±nÄ±n bir listesiyle `chat` Ã§aÄŸrÄ±sÄ± da yapabilirsiniz:

```python
from llama_index.core.llms import ChatMessage
from llama_index.llms.anthropic import Anthropic

messages = [
    ChatMessage(
        role="system", content="Sen renkli bir kiÅŸiliÄŸe sahip bir korsansÄ±n"
    ),
    ChatMessage(role="user", content="Bana bir hikaye anlat"),
]
llm = Anthropic(model="claude-sonnet-4-0")
resp = llm.chat(messages)

print(resp)
```

    assistant: Ahoy orada, ahbap! *Ã¼Ã§ kÃ¶ÅŸeli ÅŸapkasÄ±nÄ± dÃ¼zeltir ve sakalÄ±nÄ± sÄ±vazlar* 
    
    Sana denizcilik gÃ¼nlerimden, okyanusun bir krakenin Ã¶fkesi kadar vahÅŸi ve iki kat daha Ã¶ngÃ¶rÃ¼lemez olduÄŸu zamanlardan bir hikaye anlatayÄ±m!
    
    **ÅarkÄ± SÃ¶yleyen PusulanÄ±n Hikayesi**
    
    MÃ¼rettebatÄ±mla birlikte en tuhaf hazineyi keÅŸfettiÄŸimiz sisli bir sabahtÄ± - altÄ±n ya da mÃ¼cevher deÄŸil, dikkat et, deniz tÃ¼rkÃ¼leri mÄ±rÄ±ldanan bir pusula! Evet, doÄŸru duydun! Bu garip kÃ¼Ã§Ã¼k alet, hangi yÃ¶ne baktÄ±ÄŸÄ±na baÄŸlÄ± olarak farklÄ± ezgiler mÄ±rÄ±ldanÄ±rdÄ±.
    
    Kuzey, kayÄ±p aÅŸklar hakkÄ±nda melankolik bir balad getirirken, GÃ¼ney, en huysuz denizcimiz Tek GÃ¶zlÃ¼ Pete'in bile tahta bacaÄŸÄ±na tempo tutturmasÄ±na neden olan neÅŸeli bir melodi sÃ¶ylerdi. Ama iÅŸin ilginÃ§ yanÄ± ÅŸuydu - BatÄ±'yÄ± gÃ¶sterdiÄŸinde, hiÃ§birimizin daha Ã¶nce duymadÄ±ÄŸÄ±, antik bir dilde sÃ¶zleri olan gizemli bir melodi sÃ¶ylerdi.
    
    MaceracÄ± tipler olduÄŸumuz iÃ§in (ve belki biraz da aptal), bu batÄ± ÅŸarkÄ±sÄ±nÄ± Ã¼Ã§ gÃ¼n Ã¼Ã§ gece takip ettik. Pusula bizi tehlikeli sulardan, seraplar gibi parÄ±ldayan adalarÄ±n yanÄ±ndan geÃ§irdi ve sonunda suyun sÄ±vÄ± zÃ¼mrÃ¼tler gibi parladÄ±ÄŸÄ± gizli bir koya ulaÅŸtÄ±k.
    
    Ve orada, yÃ¼rekli dostum, en bÃ¼yÃ¼k hazineyi bulduk - zenginlik deÄŸil, efsunlu pusulalarÄ±nÄ± birinin iade etmesini yÃ¼zyÄ±llardÄ±r bekleyen bir deniz kÄ±zÄ± ailesi! Nezaketimizi, herhangi bir fÄ±rtÄ±nadan gÃ¼venli bir geÃ§iÅŸle ve Ã¼Ã§ gerÃ§ek hazine adasÄ±nÄ±n gizli yerleriyle Ã¶dÃ¼llendirdiler.
    
    *gÃ¶z kÄ±rpar ve hayali bir ÅŸiÅŸeden bir yudum alÄ±r*
    
    Bazen en iyi maceralar en tuhaf ÅŸarkÄ±larÄ± takip etmekten gelir, anladÄ±n mÄ±?

## AkÄ±ÅŸ (Streaming) DesteÄŸi

Her metot, `stream_` Ã¶n eki aracÄ±lÄ±ÄŸÄ±yla akÄ±ÅŸÄ± destekler.

```python
from llama_index.llms.anthropic import Anthropic

llm = Anthropic(model="claude-sonnet-4-0")

resp = llm.stream_complete("Paul Graham kimdir?")
for r in resp:
    print(r.delta, end="")
```

    Paul Graham bir bilgisayar programcÄ±sÄ±, giriÅŸimci, risk sermayedarÄ± ve denemecidir. Ä°ÅŸte tanÄ±ndÄ±ÄŸÄ± baÅŸlÄ±ca noktalar:
    
    **Y Combinator Kurucu OrtaÄŸÄ±**: 2005 yÄ±lÄ±nda dÃ¼nyanÄ±n en baÅŸarÄ±lÄ± giriÅŸim hÄ±zlandÄ±rÄ±cÄ±larÄ±ndan biri olan Y Combinator'Ä± kurmuÅŸtur. Y Combinator; Airbnb, Dropbox, Stripe, Reddit ve yÃ¼zlerce baÅŸka ÅŸirketi finanse etmiÅŸtir.
    
    **Programlama ve Lisp**: Lisp programlama dilinin gÃ¼Ã§lÃ¼ bir savunucusudur ve "On Lisp" ile "ANSI Common Lisp" dahil olmak Ã¼zere etkili kitaplar yazmÄ±ÅŸtÄ±r.
    
    **Viaweb**: 1990'larda, ilk web tabanlÄ± yazÄ±lÄ±m ÅŸirketlerinden biri olan Viaweb'i kurmuÅŸtur; ÅŸirket 1998'de Yahoo tarafÄ±ndan satÄ±n alÄ±nmÄ±ÅŸ ve Yahoo Store olmuÅŸtur.
    
    **Denemeler**: paulgraham.com adresindeki web sitesinde yayÄ±nladÄ±ÄŸÄ± giriÅŸimler, programlama ve teknoloji Ã¼zerine etkili birÃ§ok deneme yazmÄ±ÅŸtÄ±r. Denemeleri teknoloji topluluÄŸunda geniÅŸ Ã§apta okunur ve bir giriÅŸimin nasÄ±l kurulacaÄŸÄ±, neyin iyi bir programcÄ± yaptÄ±ÄŸÄ± ve inovasyonun doÄŸasÄ± gibi konularÄ± kapsar.
    
    **Sanat ve Akademi**: Harvard'da Bilgisayar Bilimi alanÄ±nda doktorasÄ± vardÄ±r ve ayrÄ±ca Rhode Island TasarÄ±m Okulu ile Floransa'daki Accademia di Belle Arti'de resim eÄŸitimi almÄ±ÅŸtÄ±r.
    
    Graham, giriÅŸim ekosistemindeki en etkili figÃ¼rlerden biri olarak kabul edilir ve giriÅŸimcilik ile teknoloji giriÅŸimleri hakkÄ±ndaki modern dÃ¼ÅŸÃ¼nceyi ÅŸekillendirmeye yardÄ±mcÄ± olmuÅŸtur.

```python
from llama_index.core.llms import ChatMessage

messages = [
    ChatMessage(role="user", content="Paul Graham kimdir?"),
]

resp = llm.stream_chat(messages)
for r in resp:
    print(r.delta, end="")
```

    Paul Graham bir bilgisayar programcÄ±sÄ±, giriÅŸimci, risk sermayedarÄ± ve denemecidir. Ä°ÅŸte tanÄ±ndÄ±ÄŸÄ± baÅŸlÄ±ca noktalar:
    
    **Y Combinator**: 2005 yÄ±lÄ±nda Airbnb, Dropbox, Stripe ve Reddit gibi ÅŸirketlerin kurulmasÄ±na yardÄ±mcÄ± olan bu oldukÃ§a etkili giriÅŸim hÄ±zlandÄ±rÄ±cÄ±sÄ±nÄ±n kurucu ortaklarÄ±ndandÄ±r. Y Combinator, erken aÅŸamadaki giriÅŸimlere tohum yatÄ±rÄ±mÄ± ve mentÃ¶rlÃ¼k saÄŸlar.
    
    **Programlama**: Programlama topluluÄŸunda saygÄ±n bir figÃ¼rdÃ¼r, Ã¶zellikle Lisp programlama dili Ã¼zerindeki Ã§alÄ±ÅŸmalarÄ±yla ve 1990'larda ilk web tabanlÄ± uygulama olan Viaweb'i (Yahoo'ya satÄ±larak Yahoo Store olmuÅŸtur) ortaklaÅŸa oluÅŸturmasÄ±yla tanÄ±nÄ±r.
    
    **YazarlÄ±k**: Graham, paulgraham.com adresindeki web sitesinde yayÄ±nladÄ±ÄŸÄ± giriÅŸimler, teknoloji, programlama ve giriÅŸimcilik Ã¼zerine dÃ¼ÅŸÃ¼nceli denemeleriyle tanÄ±nÄ±r. Denemeleri teknoloji Ã§evrelerinde geniÅŸ Ã§apta okunur ve bir giriÅŸimin nasÄ±l kurulacaÄŸÄ±, inovasyonun doÄŸasÄ± ve teknoloji trendleri gibi konularÄ± kapsar.
    
    **Etki**: Hem Y Combinator'Ä±n baÅŸarÄ±sÄ±yla hem de birÃ§ok insanÄ±n giriÅŸimcilik ve teknoloji hakkÄ±ndaki dÃ¼ÅŸÃ¼ncelerini ÅŸekillendiren yazÄ±larÄ±yla Silikon Vadisi'nin giriÅŸim ekosistemindeki en etkili kiÅŸilerden biri olarak kabul edilir.
    
    Teknik uzmanlÄ±ÄŸÄ±, iÅŸ zekasÄ± ve net yazÄ±m tarzÄ±nÄ±n kombinasyonu, onu yirmi yÄ±lÄ± aÅŸkÄ±n bir sÃ¼redir teknoloji endÃ¼strisinde Ã¶nde gelen bir ses haline getirmiÅŸtir.

## Asenkron KullanÄ±m

Her senkron metodun asenkron bir karÅŸÄ±lÄ±ÄŸÄ± vardÄ±r.

```python
from llama_index.llms.anthropic import Anthropic

llm = Anthropic(model="claude-sonnet-4-0")

resp = await llm.astream_complete("Paul Graham kimdir?")
async for r in resp:
    print(r.delta, end="")
```

    Paul Graham bir bilgisayar programcÄ±sÄ±, giriÅŸimci, risk sermayedarÄ± ve denemecidir. Ä°ÅŸte tanÄ±ndÄ±ÄŸÄ± baÅŸlÄ±ca noktalar:
    
    **Y Combinator**: 2005 yÄ±lÄ±nda Airbnb, Dropbox, Stripe ve Reddit gibi ÅŸirketlerin kurulmasÄ±na yardÄ±mcÄ± olan bu oldukÃ§a etkili giriÅŸim hÄ±zlandÄ±rÄ±cÄ±sÄ±nÄ±n kurucu ortaklarÄ±ndandÄ±r. Y Combinator, erken aÅŸamadaki giriÅŸimlere tohum yatÄ±rÄ±mÄ± ve mentÃ¶rlÃ¼k saÄŸlar.
    
    **Programlama**: Programlama topluluÄŸunda saygÄ±n bir figÃ¼rdÃ¼r, Ã¶zellikle Lisp programlama dili Ã¼zerindeki Ã§alÄ±ÅŸmalarÄ±yla tanÄ±nÄ±r. "On Lisp" ve "ANSI Common Lisp" gibi etkili kitaplar yazmÄ±ÅŸtÄ±r.
    
    **Denemeler**: Graham, paulgraham.com adresindeki web sitesinde yayÄ±nladÄ±ÄŸÄ± giriÅŸimler, teknoloji, programlama ve toplum Ã¼zerine geniÅŸ Ã§apta okunan denemeler yazar. "Do Things That Don't Scale" ve "How to Start a Startup" gibi denemeleri teknoloji dÃ¼nyasÄ±nda temel okuma parÃ§alarÄ± olarak kabul edilir.
    
    **GiriÅŸimcilik**: Y Combinator'dan Ã¶nce, 1998 yÄ±lÄ±nda Yahoo tarafÄ±ndan yaklaÅŸÄ±k 49 milyon dolara satÄ±n alÄ±nan ve Yahoo Store olan Viaweb'i (Ã§evrimiÃ§i maÄŸazalar kurmak iÃ§in ilk web tabanlÄ± uygulamalardan biri) kurmuÅŸtur.
    
    **Sanat geÃ§miÅŸi**: Ä°lginÃ§ bir ÅŸekilde, sanat alanÄ±nda da bir geÃ§miÅŸi vardÄ±r ve resim eÄŸitimi almÄ±ÅŸtÄ±r; bu deneyimi teknolojideki yaratÄ±cÄ±lÄ±k ve estetik bakÄ±ÅŸ aÃ§Ä±sÄ±nÄ± etkiler.
    
    Graham, Silikon Vadisi'nde ve daha geniÅŸ giriÅŸim ekosisteminde en etkili seslerden biri olarak kabul edilir.

```python
messages = [
    ChatMessage(role="user", content="Paul Graham kimdir?"),
]

resp = await llm.achat(messages)
print(resp)
```

    assistant: Paul Graham bir bilgisayar programcÄ±sÄ±, giriÅŸimci, risk sermayedarÄ± ve denemecidir. Ä°ÅŸte tanÄ±ndÄ±ÄŸÄ± baÅŸlÄ±ca noktalar:
    
    **Y Combinator**: 2005 yÄ±lÄ±nda Airbnb, Dropbox, Stripe ve Reddit gibi ÅŸirketlerin kurulmasÄ±na yardÄ±mcÄ± olan bu oldukÃ§a etkili giriÅŸim hÄ±zlandÄ±rÄ±cÄ±sÄ±nÄ±n kurucu ortaklarÄ±ndandÄ±r. Y Combinator, erken aÅŸamadaki giriÅŸimlere tohum yatÄ±rÄ±mÄ± ve mentÃ¶rlÃ¼k saÄŸlar.
    
    **Programlama**: Programlama topluluÄŸunda saygÄ±n bir figÃ¼rdÃ¼r, Ã¶zellikle Lisp programlama dili Ã¼zerindeki Ã§alÄ±ÅŸmalarÄ±yla ve 1990'larda ilk web tabanlÄ± uygulama olan Viaweb'i (Yahoo'ya satÄ±larak Yahoo Store olmuÅŸtur) ortaklaÅŸa oluÅŸturmasÄ±yla tanÄ±nÄ±r.
    
    **YazarlÄ±k**: Graham, paulgraham.com adresindeki web sitesinde yayÄ±nladÄ±ÄŸÄ± giriÅŸimler, teknoloji, programlama ve toplum Ã¼zerine dÃ¼ÅŸÃ¼nceli denemeleriyle tanÄ±nÄ±r. Denemeleri teknoloji Ã§evrelerinde geniÅŸ Ã§apta okunur ve bir giriÅŸimin nasÄ±l kurulacaÄŸÄ±, inovasyonun doÄŸasÄ± ve sosyal yorumlar gibi konularÄ± kapsar.
    
    **Kitaplar**: "Hackers & Painters" ve "On Lisp" dahil olmak Ã¼zere birkaÃ§ kitabÄ±n yazarÄ±dÄ±r.
    
    **Etki**: Hem Y Combinator'Ä±n etkisiyle hem de giriÅŸimcilik ve teknoloji Ã¼zerine yazÄ±larÄ±yla Silikon Vadisi'nin giriÅŸim ekosistemindeki en etkili kiÅŸilerden biri olarak kabul edilir.
    
    Graham, analitik dÃ¼ÅŸÃ¼ncesi ve iÅŸ dÃ¼nyasÄ±, teknoloji ve kÃ¼ltÃ¼r hakkÄ±ndaki aykÄ±rÄ± perspektifleriyle tanÄ±nÄ±r.



## Vertex AI DesteÄŸi

`region` ve `project_id` parametrelerini (ortam deÄŸiÅŸkenleri aracÄ±lÄ±ÄŸÄ±yla veya doÄŸrudan) saÄŸlayarak, Vertex AI Ã¼zerinden bir Anthropic modelini kullanabilirsiniz.

```python
import os

os.environ["ANTHROPIC_PROJECT_ID"] = "PROJE KÄ°MLÄ°ÄÄ°NÄ°Z BURAYA"
os.environ["ANTHROPIC_REGION"] = "PROJE BÃ–LGENÄ°Z BURAYA"
```

BÃ¶lge ve proje kimliÄŸini burada ayarlamanÄ±n, Anthropic'in Vertex AI istemcisini kullanmasÄ±nÄ± saÄŸlayacaÄŸÄ±nÄ± unutmayÄ±n.

## Bedrock DesteÄŸi

LlamaIndex ayrÄ±ca AWS Bedrock Ã¼zerinden Anthropic modellerini de destekler.

```python
from llama_index.llms.anthropic import Anthropic

# Not: Bu, ortamÄ±nÄ±zda standart AWS kimlik bilgilerinin yapÄ±landÄ±rÄ±ldÄ±ÄŸÄ±nÄ± varsayar
llm = Anthropic(
    model="anthropic.claude-3-7-sonnet-20250219-v1:0",
    aws_region="us-east-1",
)

resp = llm.complete("Paul Graham kimdir?")
```

## Ã‡ok Modlu (Multi-Modal) Destek

`ChatMessage` nesnelerini kullanarak, LLM'e gÃ¶rÃ¼ntÃ¼ler ve metinler gÃ¶nderebilirsiniz.

```python
!wget https://cdn.pixabay.com/photo/2021/12/12/20/00/play-6865967_640.jpg -O image.jpg
```

```python
from llama_index.core.llms import ChatMessage, TextBlock, ImageBlock
from llama_index.llms.anthropic import Anthropic

llm = Anthropic(model="claude-sonnet-4-0")

messages = [
    ChatMessage(
        role="user",
        blocks=[
            ImageBlock(path="image.jpg"),
            TextBlock(text="Bu gÃ¶rselde ne var?"),
        ],
    )
]

resp = llm.chat(messages)
print(resp)
```

    assistant: Bu gÃ¶rselde, koyu renkli bir kumaÅŸ yÃ¼zey Ã¼zerinde dÃ¶rt adet ahÅŸap zar gÃ¶rÃ¼lmektedir. Zarlar aÃ§Ä±k renkli ahÅŸaptan yapÄ±lmÄ±ÅŸ gibi gÃ¶rÃ¼nÃ¼yor ve her bir yÃ¼zdeki sayÄ±larÄ± belirten geleneksel siyah noktalara (pip) sahip. Koyu mavi veya siyah bir kumaÅŸ arka plan gibi gÃ¶rÃ¼nen bir yere rastgele daÄŸÄ±lmÄ±ÅŸ durumdalar.

## Ä°stem Ã–nbelleÄŸe Alma (Prompt Caching)

Anthropic modelleri, istem Ã¶nbelleÄŸe alma fikrini destekler - bu yÃ¶ntemde bir istem birden Ã§ok kez tekrarlanÄ±rsa veya bir istemin baÅŸlangÄ±cÄ± tekrarlanÄ±rsa, LLM yanÄ±tÄ± hÄ±zlandÄ±rmak ve maliyetleri dÃ¼ÅŸÃ¼rmek iÃ§in Ã¶nceden hesaplanmÄ±ÅŸ dikkat (attention) sonuÃ§larÄ±nÄ± yeniden kullanabilir.

Ä°stem Ã¶nbelleÄŸe almayÄ± etkinleÅŸtirmek iÃ§in, `ChatMessage` nesnelerinizde `cache_control` ayarÄ±nÄ± yapabilir veya her zaman ilk X mesajÄ± Ã¶nbelleÄŸe almak iÃ§in LLM Ã¼zerinde `cache_idx` ayarÄ±nÄ± yapabilirsiniz (-1 tÃ¼m mesajlar anlamÄ±na gelir).

```python
from llama_index.core.llms import ChatMessage
from llama_index.llms.anthropic import Anthropic

llm = Anthropic(model="claude-sonnet-4-0")

# mÃ¼nferit mesajlarÄ± Ã¶nbelleÄŸe al
messages = [
    ChatMessage(
        role="user",
        content="<bazÄ± Ã§ok uzun istemler>",
        additional_kwargs={"cache_control": {"type": "ephemeral"}},
    ),
]

resp = llm.chat(messages)

# ilk X mesajÄ± Ã¶nbelleÄŸe al (-1 tÃ¼m mesajlar anlamÄ±na gelir)
llm = Anthropic(model="claude-sonnet-4-0", cache_idx=-1)

resp = llm.chat(messages)
```

## YapÄ±landÄ±rÄ±lmÄ±ÅŸ Tahmin (Structured Prediction)

LlamaIndex, `structured_predict` aracÄ±lÄ±ÄŸÄ±yla herhangi bir Anthropic LLM'ini yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir LLM'e dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in sezgisel bir arayÃ¼z saÄŸlar - sadece hedef Pydantic sÄ±nÄ±fÄ±nÄ± (iÃ§ iÃ§e olabilir) tanÄ±mlayÄ±n ve bir istem verildiÄŸinde, istenen nesneyi dÄ±ÅŸarÄ± Ã§Ä±karalÄ±m.

```python
from llama_index.llms.anthropic import Anthropic
from llama_index.core.prompts import PromptTemplate
from llama_index.core.bridge.pydantic import BaseModel
from typing import List


class MenuItem(BaseModel):
    """Bir restorandaki menÃ¼ Ã¶ÄŸesi."""

    course_name: str
    is_vegetarian: bool


class Restaurant(BaseModel):
    """AdÄ±, ÅŸehri ve mutfaÄŸÄ± olan bir restoran."""

    name: str
    city: str
    cuisine: str
    menu_items: List[MenuItem]


llm = Anthropic(model="claude-sonnet-4-0")
prompt_tmpl = PromptTemplate(
    "Verilen bir ÅŸehirde ({city_name}) bir restoran oluÅŸtur"
)

# SeÃ§enek 1: `as_structured_llm` kullanÄ±n
restaurant_obj = (
    llm.as_structured_llm(Restaurant)
    .complete(prompt_tmpl.format(city_name="Miami"))
    .raw
)
# SeÃ§enek 2: `structured_predict` kullanÄ±n
# restaurant_obj = llm.structured_predict(Restaurant, prompt_tmpl, city_name="Miami")
```

```python
restaurant_obj
```

    Restaurant(name='Ocean Breeze Bistro', city='Miami', cuisine='Seafood', menu_items=[MenuItem(course_name='Grilled Mahi-Mahi with Mango Salsa', is_vegetarian=False), MenuItem(course_name='Coconut Shrimp with Pineapple Dipping Sauce', is_vegetarian=False), MenuItem(course_name='Quinoa and Black Bean Bowl', is_vegetarian=True), MenuItem(course_name='Key Lime Pie', is_vegetarian=True), MenuItem(course_name='Lobster Bisque', is_vegetarian=False), MenuItem(course_name='Grilled Vegetable Platter with Chimichurri', is_vegetarian=True)])

#### AkÄ±ÅŸlÄ± YapÄ±landÄ±rÄ±lmÄ±ÅŸ Tahmin (Structured Prediction with Streaming)

`as_structured_llm` ile sarmalanmÄ±ÅŸ herhangi bir LLM, `stream_chat` aracÄ±lÄ±ÄŸÄ±yla akÄ±ÅŸÄ± destekler.

```python
from llama_index.core.llms import ChatMessage
from IPython.display import clear_output
from pprint import pprint

input_msg = ChatMessage.from_str("San Francisco'da bir restoran oluÅŸtur")

sllm = llm.as_structured_llm(Restaurant)
stream_output = sllm.stream_chat([input_msg])
for partial_output in stream_output:
    clear_output(wait=True)
    pprint(partial_output.raw.dict())
    restaurant_obj = partial_output.raw

restaurant_obj
```

    {'city': 'San Francisco',
     'cuisine': 'California Fusion',
     'menu_items': [{'course_name': 'Dungeness Crab Cakes', 'is_vegetarian': False},
                    {'course_name': 'Roasted Beet and Arugula Salad',
                     'is_vegetarian': True},
                    {'course_name': 'Grilled Pacific Salmon',
                     'is_vegetarian': False},
                    {'course_name': 'Wild Mushroom Risotto', 'is_vegetarian': True},
                    {'course_name': 'Grass-Fed Beef Tenderloin',
                     'is_vegetarian': False},
                    {'course_name': 'Chocolate Lava Cake', 'is_vegetarian': True}],
     'name': 'Golden Gate Bistro'}

    Restaurant(name='Golden Gate Bistro', city='San Francisco', cuisine='California Fusion', menu_items=[MenuItem(course_name='Dungeness Crab Cakes', is_vegetarian=False), MenuItem(course_name='Roasted Beet and Arugula Salad', is_vegetarian=True), MenuItem(course_name='Grilled Pacific Salmon', is_vegetarian=False), MenuItem(course_name='Wild Mushroom Risotto', is_vegetarian=True), MenuItem(course_name='Grass-Fed Beef Tenderloin', is_vegetarian=False), MenuItem(course_name='Chocolate Lava Cake', is_vegetarian=True)])




## Model DÃ¼ÅŸÃ¼nme (Model Thinking)

`claude-3.7 Sonnet` ile, modelin bir gÃ¶rev hakkÄ±nda daha derin "dÃ¼ÅŸÃ¼nmesini" saÄŸlayabilir ve nihai cevabÄ± yazmadan Ã¶nce bir dÃ¼ÅŸÃ¼nce zinciri (chain-of-thought) yanÄ±tÄ± Ã¼retmesini temin edebilirsiniz.

Bunu, yapÄ±cÄ±ya (constructor) `thinking_dict` parametresini geÃ§irerek ve dÃ¼ÅŸÃ¼nme sÃ¼reci iÃ§in ayrÄ±lacak belirteÃ§ miktarÄ±nÄ± belirterek etkinleÅŸtirebilirsiniz.

```python
from llama_index.llms.anthropic import Anthropic
from llama_index.core.llms import ChatMessage

llm = Anthropic(
    model="claude-sonnet-4-0",
    # max_tokens, budget_tokens'tan bÃ¼yÃ¼k olmalÄ±dÄ±r
    max_tokens=64000,
    # dÃ¼ÅŸÃ¼nmenin Ã§alÄ±ÅŸmasÄ± iÃ§in temperature 1.0 olmalÄ±dÄ±r
    temperature=1.0,
    thinking_dict={"type": "enabled", "budget_tokens": 1600},
)
```

```python
messages = [
    ChatMessage(role="user", content="(1234 * 3421) / (231 + 2341) = ?")
]

resp_gen = llm.stream_chat(messages)

for r in resp_gen:
    print(r.delta, end="")

print()
print(r.message.content)
```

    Bunu adÄ±m adÄ±m Ã§Ã¶zeceÄŸim.
    
    Ã–nce, payÄ± hesaplayalÄ±m:
    1234 Ã— 3421 = 4.221.514
    
    Sonra, paydayÄ± hesaplayalÄ±m:
    231 + 2341 = 2.572
    
    Åimdi bÃ¶lme iÅŸlemini yapabilirim:
    4.221.514 Ã· 2.572 = 1.641,42 (2 ondalÄ±k basamaÄŸa yuvarlanmÄ±ÅŸ)
    
    DolayÄ±sÄ±yla: (1234 Ã— 3421) Ã· (231 + 2341) = **1.641,42**
    Bunu adÄ±m adÄ±m Ã§Ã¶zeceÄŸim.
    
    Ã–nce, payÄ± hesaplayalÄ±m:
    1234 Ã— 3421 = 4.221.514
    
    Sonra, paydayÄ± hesaplayalÄ±m:
    231 + 2341 = 2.572
    
    Åimdi bÃ¶lme iÅŸlemini yapabilirim:
    4.221.514 Ã· 2.572 = 1.641,42 (2 ondalÄ±k basamaÄŸa yuvarlanmÄ±ÅŸ)
    
    DolayÄ±sÄ±yla: (1234 Ã— 3421) Ã· (231 + 2341) = **1.641,42**

```python
print(r.message.additional_kwargs["thinking"]["signature"])
```

    EsgICkYIAxgCKkBcW71ZZ3zt/vVxd0Aw2evRNOsyewVAaXXFcHa2zRC5O/TG/Db+RfgHqKNF7EWL0WuJKRXJZ20Y/...

Tam dÃ¼ÅŸÃ¼nme sÃ¼recini de ortaya Ã§Ä±karabiliriz:

```python
print(r.message.additional_kwargs["thinking"]["thinking"])
```

    (1234 * 3421) / (231 + 2341) iÅŸlemini hesaplamam gerekiyor.
    
    AdÄ±m adÄ±m yapayÄ±m.
    
    Ã–nce payÄ± hesaplayalÄ±m: 1234 * 3421
    1234 * 3421
    = 1234 * (3000 + 400 + 20 + 1)
    = 1234 * 3000 + 1234 * 400 + 1234 * 20 + 1234 * 1
    = 3.702.000 + 493.600 + 24.680 + 1.234
    = 4.221.514
    
    Åimdi paydayÄ± hesaplayalÄ±m: 231 + 2341
    231 + 2341 = 2.572
    
    Ä°ÅŸlem ÅŸuna dÃ¶nÃ¼ÅŸÃ¼yor:
    4.221.514 / 2.572
    
    BÃ¶lmeyi yapalÄ±m:
    4.221.514 Ã· 2.572 = 1.641,4...
    
    Daha kesin olalÄ±m:
    4.221.514 Ã· 2.572 = 1.641,42...
    
    AslÄ±nda Ã§arpmamÄ± tekrar kontrol edeyim:
    1234 * 3421
    
    1234
    Ã—3421
    -----
    1234 (1234 Ã— 1)
    2468 (1234 Ã— 2, bir basamak kaydÄ±rÄ±lmÄ±ÅŸ)
    4936 (1234 Ã— 4, iki basamak kaydÄ±rÄ±lmÄ±ÅŸ)
    3702 (1234 Ã— 3, Ã¼Ã§ basamak kaydÄ±rÄ±lmÄ±ÅŸ)
    -----
    
    Daha dikkatli olayÄ±m:
    1234 Ã— 1 = 1234
    1234 Ã— 20 = 24680
    1234 Ã— 400 = 493600
    1234 Ã— 3000 = 3702000
    
    1234 + 24680 + 493600 + 3702000 = 4.221.514
    
    Bu doÄŸru.
    
    Åimdi 4.221.514 Ã· 2.572 â‰ˆ 1.641,42

## AraÃ§/Fonksiyon Ã‡aÄŸÄ±rma (Tool/Function Calling)

Anthropic, API Ã¼zerinden doÄŸrudan araÃ§/fonksiyon Ã§aÄŸÄ±rmayÄ± destekler. LlamaIndex kullanarak bazÄ± temel otonom araÃ§ Ã§aÄŸÄ±rma modellerini uygulayabiliriz.

```python
from llama_index.core.tools import FunctionTool
from llama_index.core.llms import ChatMessage
from llama_index.llms.anthropic import Anthropic
from datetime import datetime

llm = Anthropic(model="claude-sonnet-4-0")


def get_current_time() -> dict:
    """Mevcut saati getirir"""
    return {"time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")}


# aracÄ± tanÄ±mlamak iÃ§in araÃ§ adÄ±nÄ±, varsa tip ek aÃ§Ä±klamalarÄ±nÄ± ve docstring'i kullanÄ±r
tool = FunctionTool.from_defaults(fn=get_current_time)
```

AracÄ± Ã§aÄŸÄ±rmak ve sonucu almak iÃ§in basitÃ§e tek bir geÃ§iÅŸ yapabiliriz:

```python
resp = llm.predict_and_call([tool], "Åu an saat kaÃ§?")
print(resp)
```

    {'time': '2025-05-22 12:45:48'}

Otonom bir araÃ§ Ã§aÄŸÄ±rma dÃ¶ngÃ¼sÃ¼ uygulamak iÃ§in daha dÃ¼ÅŸÃ¼k seviyeli API'leri de kullanabiliriz!

```python
chat_history = [ChatMessage(role="user", content="Åu an saat kaÃ§?")]
tools_by_name = {t.metadata.name: t for t in [tool]}

resp = llm.chat_with_tools([tool], chat_history=chat_history)
tool_calls = llm.get_tool_calls_from_response(
    resp, error_on_no_tool_call=False
)

if not tool_calls:
    print(resp)
else:
    while tool_calls:
        # LLM'in yanÄ±tÄ±nÄ± sohbet geÃ§miÅŸine ekle
        chat_history.append(resp.message)

        for tool_call in tool_calls:
            tool_name = tool_call.tool_name
            tool_kwargs = tool_call.tool_kwargs

            print(f"{tool_name} aracÄ± {tool_kwargs} ile Ã§aÄŸrÄ±lÄ±yor")
            tool_output = tool.call(**tool_kwargs)
            print("AraÃ§ Ã§Ä±ktÄ±sÄ±: ", tool_output)
            chat_history.append(
                ChatMessage(
                    role="tool",
                    content=str(tool_output),
                    # Anthropic, OpenAI vb. Ã§oÄŸu LLM'in araÃ§ Ã§aÄŸrÄ± kimliÄŸini (id) bilmesi gerekir
                    additional_kwargs={"tool_call_id": tool_call.tool_id},
                )
            )

            resp = llm.chat_with_tools([tool], chat_history=chat_history)
            tool_calls = llm.get_tool_calls_from_response(
                resp, error_on_no_tool_call=False
            )
    print("Nihai yanÄ±t: ", resp.message.content)
```

    get_current_time aracÄ± {} ile Ã§aÄŸrÄ±lÄ±yor
    AraÃ§ Ã§Ä±ktÄ±sÄ±:  {'time': '2025-05-22 12:45:51'}
    Nihai yanÄ±t:  Åu anki saat 22 MayÄ±s 2025, 12:45:51.

## Sunucu TarafÄ± AraÃ§ Ã‡aÄŸÄ±rma (Server-Side Tool Calling)

Anthropic artÄ±k en yeni sÃ¼rÃ¼mlerde sunucu tarafÄ± araÃ§ Ã§aÄŸÄ±rmayÄ± da destekliyor.

Ä°ÅŸte bunun nasÄ±l kullanÄ±lacaÄŸÄ±na dair bir Ã¶rnek:

```python
from llama_index.llms.anthropic import Anthropic

llm = Anthropic(
    model="claude-sonnet-4-0",
    max_tokens=1024,
    tools=[
        {
            "type": "web_search_20250305",
            "name": "web_search",
            "max_uses": 3,  # Maksimum 3 arama ile sÄ±nÄ±rla
        }
    ],
)

# AtÄ±flar (citations) ile yanÄ±t al
response = llm.complete("En son yapay zeka araÅŸtÄ±rma trendleri nelerdir?")

# Ana yanÄ±t iÃ§eriÄŸine eriÅŸ
print(response.text)

# Varsa atÄ±flara eriÅŸ
for citation in response.citations:
    print(f"Kaynak: {citation.get('url')} - {citation.get('cited_text')}")
```

    En son araÅŸtÄ±rma ve endÃ¼stri raporlarÄ±na dayanarak, 2025'i ÅŸekillendiren temel yapay zeka trendleri ÅŸunlardÄ±r:
    
    ## 1. Otonom YZ (Agentic AI) Ã–n Plana Ã‡Ä±kÄ±yor
    
    Otonom YZ - asgari insan mÃ¼dahalesiyle baÄŸÄ±msÄ±z olarak gÃ¶revleri yerine getirebilen YZ sistemleri - 2025'in en Ã¶nemli trendi olarak ortaya Ã§Ä±kÄ±yor. Microsoft yÃ¶neticilerine gÃ¶re, "aracÄ±larÄ± (agent) YZ Ã§aÄŸÄ±nÄ±n uygulamalarÄ± olarak dÃ¼ÅŸÃ¼nÃ¼n." Erken uygulamalar, parola deÄŸiÅŸiklikleri veya izin talepleri gibi kÃ¼Ã§Ã¼k, yapÄ±landÄ±rÄ±lmÄ±ÅŸ dahili gÃ¶revlere odaklanacak; ÅŸirketler ise gerÃ§ek para iÃ§eren mÃ¼ÅŸteri odaklÄ± etkinlikler iÃ§in aracÄ±larÄ± kullanma konusunda temkinli davranacak.
    
    ## 2. GeliÅŸmiÅŸ Muhakeme Yetenekleri
    
    OpenAI'nin o1 modeli gibi geliÅŸmiÅŸ muhakeme yeteneklerine sahip YZ modelleri, karmaÅŸÄ±k problemleri insan dÃ¼ÅŸÃ¼ncesine benzer mantÄ±ksal adÄ±mlarla Ã§Ã¶zebilir; bu da onlarÄ± Ã¶zellikle bilim, kodlama, matematik, hukuk ve tÄ±p alanlarÄ±nda yararlÄ± kÄ±lar. Teknoloji ÅŸirketleri, doÄŸal dil iÅŸleme, gÃ¶rÃ¼ntÃ¼ oluÅŸturma ve kodlama alanlarÄ±nda sÄ±nÄ±rlarÄ± zorlayan Ã¶ncÃ¼ modeller geliÅŸtirmek iÃ§in yarÄ±ÅŸÄ±yor.
    
    ## 3. Ã–lÃ§Ã¼lebilir ROI ve Kurumsal Benimsemeye Odaklanma
    
    2025'te iÅŸletmeler, Ã¼retken YZ'den Ã¶lÃ§Ã¼lebilir sonuÃ§lar bekliyor: maliyetlerin dÃ¼ÅŸÃ¼rÃ¼lmesi, kanÄ±tlanabilir yatÄ±rÄ±m getirisi (ROI) ve verimlilik artÄ±ÅŸÄ±. KuruluÅŸlarÄ±n %90'Ä±ndan fazlasÄ±nÄ±n Ã¼retken YZ kullanÄ±mÄ±nÄ± artÄ±rmasÄ±na raÄŸmen, giriÅŸimlerini sadece %8'inin olgun saymasÄ±, pratik uygulamada Ã¶nemli bir bÃ¼yÃ¼me alanÄ± olduÄŸunu gÃ¶steriyor.
    
    ## 4. Bilimsel KeÅŸif ve Malzeme Bilimi
    
    YZ, bilimsel keÅŸiflerde giderek daha fazla uygulanÄ±yor; malzeme bilimi, YZ'nin protein araÅŸtÄ±rmalarÄ±ndaki baÅŸarÄ±sÄ±nÄ±n ardÄ±ndan gelecek vaat eden bir alan olarak ortaya Ã§Ä±kÄ±yor. Meta, bilim insanlarÄ±nÄ±n yeni malzemeleri daha hÄ±zlÄ± keÅŸfetmelerine yardÄ±mcÄ± olmak iÃ§in devasa veri kÃ¼meleri ve modeller yayÄ±nladÄ±.
    
    ## 5. Ã‡ok Modlu YZ ve Sohbet RobotlarÄ±nÄ±n Ã–tesi
    
    YZ teknolojisi olgunlaÅŸtÄ±kÃ§a, geliÅŸtiriciler ve iÅŸletmeler, sohbet robotlarÄ±nÄ± baÄŸÄ±msÄ±z araÃ§lar olarak kullanmak yerine bÃ¼yÃ¼k dil modellerinin Ã¼zerine geliÅŸmiÅŸ yazÄ±lÄ±m uygulamalarÄ± oluÅŸturmaya yÃ¶neliyor.
    
    ## 6. Dramatik Maliyet DÃ¼ÅŸÃ¼ÅŸleri
    
    Ã‡Ä±karÄ±m (inference) maliyetleri hÄ±zla dÃ¼ÅŸÃ¼yor - bir yÄ±ldan kÄ±sa bir sÃ¼rede milyon belirteÃ§ baÅŸÄ±na 20 dolardan 0,07 dolara geriledi; GPT-3.5 dÃ¼zeyindeki performans maliyeti KasÄ±m 2022 ile Ekim 2024 arasÄ±nda 280 kattan fazla azaldÄ±.
    
    ## 7. Performans FarklarÄ±nÄ±n KapanmasÄ±
    
    En iyi ABD ve Ã‡in YZ modelleri arasÄ±ndaki performans farkÄ± bir yÄ±l iÃ§inde %9,26'dan sadece %1,70'e indi; aÃ§Ä±k aÄŸÄ±rlÄ±klÄ± modeller ise kapalÄ± modellerle aradaki farkÄ± kapatÄ±yor ve bazÄ± kÄ±yaslamalarda performans farkÄ±nÄ± %8'den %1,7'ye indiriyor.
    
    ## 8. Artan DÃ¼zenleyici Faaliyetler
    
    ABD federal kurumlarÄ± 2024'te 59 YZ ile ilgili dÃ¼zenleme getirdi - bu sayÄ± 2023'tekinin iki katÄ±ndan fazla - kÃ¼resel Ã§apta ise YZ'den bahseden yasal dÃ¼zenlemeler 75 Ã¼lkede %21,3 arttÄ±.
    
    ## 9. Veri YÃ¶netimi Devrimi
    
    Ãœretken YZ, yapÄ±landÄ±rÄ±lmamÄ±ÅŸ verileri yeniden Ã¶nemli hale getiriyor; veri ve YZ liderlerinin %94'Ã¼ YZ ilgisinin veriye olan odaÄŸÄ± artÄ±rdÄ±ÄŸÄ±nÄ±, veri gÃ¶llerinin esnekliÄŸini veri ambarlarÄ±nÄ±n yapÄ±sÄ±yla birleÅŸtiren bir "veri gÃ¶l evi devrimi"ni tetiklediÄŸini sÃ¶ylÃ¼yor.
    
    ## 10. Savunma ve Askeri Uygulamalar
    
    Savunma teknolojisi ÅŸirketleri, YZ modellerini eÄŸitmek iÃ§in gizli askeri verilerden yararlanÄ±yor; OpenAI gibi ana akÄ±m YZ ÅŸirketleri askeri ortaklÄ±klara yÃ¶nelerek Pentagon ile Ã§alÄ±ÅŸan Microsoft, Amazon ve Google arasÄ±na katÄ±lÄ±yor.
    
    Bu trendler 2025'i gÃ¶steriyor...
    Kaynak: https://news.microsoft.com/source/features/ai/6-ai-trends-youll-see-more-of-in-2025/ - Â· YZ destekli aracÄ±lar, evde ve iÅŸte hayatÄ±nÄ±zÄ± basitleÅŸtirmeye yardÄ±mcÄ± olmak iÃ§in daha fazla Ã¶zerklikle daha fazlasÄ±nÄ± yapacak. 
    Kaynak: https://news.microsoft.com/source/features/ai/6-ai-trends-youll-see-more-of-in-2025/ - 2025'te yeni nesil YZ destekli aracÄ±lar daha fazlasÄ±nÄ± yapacak - hatta sizin adÄ±nÄ±za belirli gÃ¶revleri yÃ¼rÃ¼tecek.  
    Kaynak: https://sloanreview.mit.edu/article/five-trends-in-ai-and-data-science-for-2025/ - Otonom YZ'yi -baÄŸÄ±msÄ±z olarak gÃ¶rev yapan YZ tÃ¼rÃ¼- Ã¶nceden aradan Ã§Ä±karalÄ±m: 2025'in "en trend YZ trendi" olacaÄŸÄ± kesin. 
    Kaynak: https://news.microsoft.com/source/features/ai/6-ai-trends-youll-see-more-of-in-2025/ - Microsoft'un iÅŸ ve sektÃ¶r Copilot kurumsal baÅŸkan yardÄ±mcÄ±sÄ± Charles Lamanna, "AracÄ±larÄ± YZ Ã§aÄŸÄ±nÄ±n uygulamalarÄ± olarak dÃ¼ÅŸÃ¼nÃ¼n," diyor.
    Kaynak: https://sloanreview.mit.edu/article/five-trends-in-ai-and-data-science-for-2025/ - Ä°lk aracÄ±lar, az miktarda paranÄ±n sÃ¶z konusu olduÄŸu kÃ¼Ã§Ã¼k, yapÄ±landÄ±rÄ±lmÄ±ÅŸ dahili gÃ¶revler iÃ§in olanlar olacak - Ã¶rneÄŸin, parolanÄ±zÄ± deÄŸiÅŸtirmenize yardÄ±mcÄ± olmak...
    Kaynak: https://news.microsoft.com/source/features/ai/6-ai-trends-youll-see-more-of-in-2025/ - OpenAI o1 gibi geliÅŸmiÅŸ muhakeme yeteneklerine sahip modeller, karmaÅŸÄ±k problemleri insanlarÄ±n dÃ¼ÅŸÃ¼nme ÅŸekline benzer mantÄ±ksal adÄ±mlarla zaten Ã§Ã¶zebiliyor...
    Kaynak: https://www.morganstanley.com/insights/articles/ai-trends-reasoning-frontier-models-2025-tmt - DÃ¼nyanÄ±n en bÃ¼yÃ¼k teknoloji ÅŸirketleri yapay zeka kullanÄ±mÄ± iÃ§in en son teknolojileri geliÅŸtirmek Ã¼zere yarÄ±ÅŸÄ±yorlar: bÃ¼yÃ¼k dil modellerinin akÄ±l yÃ¼rÃ¼tme yeteneÄŸi...
    Kaynak: https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends - 2025'te iÅŸletmelerin Ã¼retken YZ'den Ã¶lÃ§Ã¼lebilir sonuÃ§lar: maliyet dÃ¼ÅŸÃ¼ÅŸleri, kanÄ±tlanabilir ROI ve verimlilik kazanÄ±mlarÄ± iÃ§in daha fazla baskÄ± yapmasÄ±nÄ± bekleyin. 
    Kaynak: https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends - 2025'te iÅŸletmelerin Ã¼retken YZ'den Ã¶lÃ§Ã¼lebilir sonuÃ§lar: maliyet dÃ¼ÅŸÃ¼ÅŸleri, kanÄ±tlanabilir ROI ve verimlilik kazanÄ±mlarÄ± iÃ§in daha fazla baskÄ± yapmasÄ±nÄ± bekleyin. 
    Kaynak: https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends - EylÃ¼l 2024 tarihli bir araÅŸtÄ±rma raporunda, Informa TechTargetâ€™Ä±n Enterprise Strategy Group ekibi, kuruluÅŸlarÄ±n %90â€™Ä±ndan fazlasÄ±nÄ±n Ã¼retken YZ kullanÄ±mÄ±nÄ± artÄ±rmasÄ±na raÄŸmen...
    Kaynak: https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/ - Bu eÄŸilimin gelecek yÄ±l da devam etmesini ve Ã¶zellikle bilimsel keÅŸifleri amaÃ§layan daha fazla veri kÃ¼mesi ve model gÃ¶rmeyi bekleyin. 
    Kaynak: https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/ - Potansiyel alanlardan biri malzeme bilimi. Meta, bilim insanlarÄ±nÄ±n yeni malzemeleri Ã§ok daha hÄ±zlÄ± keÅŸfetmek iÃ§in YZ kullanmalarÄ±na yardÄ±mcÄ± olabilecek devasa veri kÃ¼meleri ve modeller yayÄ±nladÄ±...
    Kaynak: https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/ - Meta, bilim insanlarÄ±nÄ±n yeni malzemeleri Ã§ok daha hÄ±zlÄ± keÅŸfetmek iÃ§in YZ kullanmalarÄ±na yardÄ±mcÄ± olabilecek devasa veri kÃ¼meleri ve modeller yayÄ±nladÄ± ve AralÄ±k ayÄ±nda Hugging Face...
    Kaynak: https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends - Ancak teknoloji olgunlaÅŸtÄ±kÃ§a, YZ geliÅŸtiricileri, son kullanÄ±cÄ±lar ve iÅŸletme mÃ¼ÅŸterileri sohbet robotlarÄ±nÄ±n Ã¶tesine bakÄ±yor. "Ä°nsanlarÄ±n daha yaratÄ±cÄ± dÃ¼ÅŸÃ¼nmesi gerekiyor..."
    Kaynak: https://spectrum.ieee.org/ai-index-2025 - Bu, Ã§Ä±karÄ±m maliyetlerinin veya eÄŸitilmiÅŸ bir modeli sorgulama maliyetinin dramatik bir ÅŸekilde dÃ¼ÅŸtÃ¼ÄŸÃ¼ anlamÄ±na geliyor. 
    Kaynak: https://spectrum.ieee.org/ai-index-2025 - Rapor, mavi Ã§izginin milyon belirteÃ§ baÅŸÄ±na 20 dolardan 0,07 dolara dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼; pembe Ã§izginin ise 15 dolardan dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ gÃ¶steriyor...
    Kaynak: https://hai.stanford.edu/ai-index/2025-ai-index-report - Giderek daha yetenekli hale gelen kÃ¼Ã§Ã¼k modellerin etkisiyle, GPT-3.5 seviyesinde performans gÃ¶steren bir sistemin Ã§Ä±karÄ±m maliyeti KasÄ±m 2022'den bu yana 280 kattan fazla dÃ¼ÅŸtÃ¼...
    Kaynak: https://spectrum.ieee.org/ai-index-2025 - Ocak 2024'te en iyi ABD modeli en iyi Ã‡in modelinden %9,26 daha iyi performans gÃ¶steriyordu; Åubat 2025 itibarÄ±yla bu fark sadece %1,70'e indi....
    Kaynak: https://hai.stanford.edu/ai-index/2025-ai-index-report - AÃ§Ä±k aÄŸÄ±rlÄ±klÄ± modeller de kapalÄ± modellerle aradaki farkÄ± kapatÄ±yor ve bazÄ± kÄ±yaslamalarda performans farkÄ±nÄ± tek bir yÄ±lda %8'den sadece %1,7'ye indiriyor...
    Kaynak: https://hai.stanford.edu/ai-index/2025-ai-index-report - 2024 yÄ±lÄ±nda ABD federal kurumlarÄ± 59 yapay zeka baÄŸlantÄ±lÄ± dÃ¼zenleme getirdi - bu rakam 2023'tekinin iki katÄ±ndan fazla - ve bu dÃ¼zenlemeler iki kat daha fazla kurum tarafÄ±ndan yayÄ±nlandÄ±. KÃ¼resel olarak...
    Kaynak: https://sloanreview.mit.edu/article/five-trends-in-ai-and-data-science-for-2025/ - Ãœretken YZ'nin kuruluÅŸlar Ã¼zerinde baÅŸka bir etkisi daha oldu: YapÄ±landÄ±rÄ±lmamÄ±ÅŸ verileri yeniden Ã¶nemli hale getiriyor. 2025 YZ ve Veri LiderliÄŸi YÃ¶netici AraÅŸtÄ±rmasÄ±'nda...
    Kaynak: https://www.morganstanley.com/insights/articles/ai-trends-reasoning-frontier-models-2025-tmt - YÃ¶neticiler ayrÄ±ca veri gÃ¶llerinin dÃ¼ÅŸÃ¼k maliyetli depolamasÄ± ve esnekliÄŸini veri ambarlarÄ±nÄ±n yapÄ±sÄ±yla birleÅŸtiren birleÅŸik veri platformlarÄ± oluÅŸturma eÄŸilimi olan "veri gÃ¶l evi devrimi"ni vurguladÄ±lar...
    Kaynak: https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/ - 2025 yÄ±lÄ±nda bu trendler, ÅŸu anda gizli askeri verilerden yararlanan Palantir, Anduril ve diÄŸerleri gibi savunma teknolojisi ÅŸirketleri iÃ§in bir nimet olmaya devam edecek...


## AraÃ§ Ã‡aÄŸÄ±rma + AtÄ±flar (Tool Calling + Citations)

`llama-index-core>=0.12.46` + `llama-index-llms-anthropic>=0.7.6` sÃ¼rÃ¼mlerinde, atÄ±f yapÄ±labilir araÃ§ sonuÃ§larÄ±nÄ± Ã§Ä±ktÄ± olarak verme desteÄŸi ekledik!

Anthropic kullanarak, artÄ±k araÃ§ sonuÃ§larÄ±nÄ±zÄ±n belirli bÃ¶lÃ¼mlerine atÄ±f yapmak iÃ§in sunucu tarafÄ± atÄ±flarÄ±ndan yararlanabilirsiniz.

EÄŸer LLM bir araÃ§ sonucuna atÄ±f yaparsa, atÄ±f Ã§Ä±ktÄ±da kaynak, baÅŸlÄ±k ve atÄ±f yapÄ±lan iÃ§eriÄŸi iÃ§eren bir `CitationBlock` olarak gÃ¶rÃ¼necektir.

Bunu pratikte yapmanÄ±n birkaÃ§ yolunu inceleyelim.

Ä°lk olarak, atÄ±f yapÄ±labilir bir blok dÃ¶ndÃ¼ren bir taslak (dummy) araÃ§/fonksiyon tanÄ±mlayalÄ±m.

```python
from llama_index.core import Document
from llama_index.core.llms import CitableBlock, TextBlock
from llama_index.core.tools import FunctionTool

dummy_text = Document.example().text


async def search_fn(query: str):
    """SorularÄ± yanÄ±tlamak iÃ§in web'de arama yapmak iÃ§in kullanÄ±ÅŸlÄ±dÄ±r."""
    return CitableBlock(
        content=[TextBlock(text=dummy_text)],
        title="LLM'ler ve LlamaIndex HakkÄ±nda GerÃ§ekler",
        source="https://docs.llamaindex.ai",
    )


search_tool = FunctionTool.from_defaults(search_fn)
```

```python
from llama_index.llms.anthropic import Anthropic

llm = Anthropic(
    model="claude-sonnet-4-0",
    # api_key="sk-...",
)
```

### AracÄ±lar + AtÄ±f YapÄ±labilir AraÃ§lar

Ã‡Ä±ktÄ±da aynÄ± atÄ±flarÄ± almak iÃ§in bu araÃ§larÄ± doÄŸrudan `FunctionAgent` gibi Ã¶nceden oluÅŸturulmuÅŸ aracÄ±larda da kullanabilirsiniz.

```python
from llama_index.core.agent.workflow import FunctionAgent

agent = FunctionAgent(
    tools=[search_tool],
    llm=llm,
    # Statik bir sonuÃ§ dÃ¶ndÃ¼ren sahte bir aracÄ±mÄ±z olduÄŸu iÃ§in LLM belirteÃ§lerini boÅŸa harcamak istemiyoruz
    system_prompt="KullanÄ±cÄ± mesajÄ± baÅŸÄ±na yalnÄ±zca bir arama sorgusu yapÄ±n.",
    timeout=None,
)
```

```python
output = await agent.run("LlamaIndex ve LLM'ler birlikte nasÄ±l Ã§alÄ±ÅŸÄ±r?")
```

```python
from llama_index.core.llms import CitationBlock

print(output.response.content)
print("----" * 20)
for block in output.response.blocks:
    if isinstance(block, CitationBlock):
        print("Kaynak: ", block.source)
        print("BaÅŸlÄ±k: ", block.title)
        print("AtÄ±f YapÄ±lan Ä°Ã§erik:\n", block.cited_content.text)
        print("----" * 20)
```

    Arama sonuÃ§larÄ±na dayanarak, LlamaIndex ve LLM'lerin birlikte nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± aÃ§Ä±klayabilirim:
    
    LLM'ler, bilgi oluÅŸturma ve muhakeme iÃ§in olaÄŸanÃ¼stÃ¼ bir teknoloji parÃ§asÄ±dÄ±r. BÃ¼yÃ¼k miktarda halka aÃ§Ä±k veri Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸlerdir. Ancak temel bir zorluk vardÄ±r: LLM'leri kendi Ã¶zel verilerimizle en iyi nasÄ±l gÃ¼Ã§lendirebiliriz?
    
    Ä°ÅŸte LlamaIndex burada Ã§Ã¶zÃ¼m olarak devreye giriyor. LlamaIndex, LLM uygulamalarÄ± oluÅŸturmanÄ±za yardÄ±mcÄ± olacak bir "veri Ã§erÃ§evesidir" (data framework). Birlikte ÅŸu ÅŸekilde Ã§alÄ±ÅŸÄ±rlar:
    
    ## Veri Entegrasyonu ve YapÄ±sÄ±
    LlamaIndex, mevcut veri kaynaklarÄ±nÄ±zÄ± ve veri formatlarÄ±nÄ±zÄ± (API'ler, PDF'ler, belgeler, SQL vb.) almak iÃ§in veri baÄŸlayÄ±cÄ±larÄ± sunar ve bu verilerin LLM'lerle kolayca kullanÄ±labilmesi iÃ§in verilerinizi yapÄ±landÄ±rma yollarÄ± (indeksler, grafikler) saÄŸlar.
    
    ## GeliÅŸmiÅŸ Sorgu ArayÃ¼zÃ¼
    LlamaIndex, verileriniz Ã¼zerinde geliÅŸmiÅŸ bir eriÅŸim/sorgu arayÃ¼zÃ¼ saÄŸlar: Herhangi bir LLM giriÅŸ istemini besleyin, geri eriÅŸilen baÄŸlamÄ± ve bilgiyle gÃ¼Ã§lendirilmiÅŸ Ã§Ä±ktÄ±yÄ± alÄ±n. Bu, bir soru sorduÄŸunuzda LlamaIndex'in Ã¶zel verilerinizden ilgili bilgileri aldÄ±ÄŸÄ± ve bunu LLM'e baÄŸlam olarak sunduÄŸu, bÃ¶ylece daha doÄŸru ve kiÅŸiselleÅŸtirilmiÅŸ yanÄ±tlar saÄŸladÄ±ÄŸÄ± anlamÄ±na gelir.
    
    ## Esnek Entegrasyon
    LlamaIndex, dÄ±ÅŸ uygulama Ã§erÃ§evenizle (Ã¶rneÄŸin LangChain, Flask, Docker, ChatGPT, baÅŸka herhangi bir ÅŸeyle) kolay entegrasyonlar saÄŸlar.
    
    ## KullanÄ±cÄ± Dostu TasarÄ±m
    LlamaIndex hem baÅŸlangÄ±Ã§ seviyesindeki kullanÄ±cÄ±lar hem de ileri dÃ¼zey kullanÄ±cÄ±lar iÃ§in araÃ§lar saÄŸlar. Ãœst dÃ¼zey API, yeni baÅŸlayanlarÄ±n LlamaIndex'i kullanarak verilerini 5 satÄ±r kodla almalarÄ±na ve sorgulamalarÄ±na olanak tanÄ±r. Alt seviye API'ler, ileri dÃ¼zey kullanÄ±cÄ±larÄ±n herhangi bir modÃ¼lÃ¼ (veri baÄŸlayÄ±cÄ±larÄ±, indeksler, alÄ±cÄ±lar, sorgu motorlarÄ±, yeniden sÄ±ralama modÃ¼lleri) ihtiyaÃ§larÄ±na gÃ¶re Ã¶zelleÅŸtirmesine ve geniÅŸletmesine olanak tanÄ±r.
    --------------------------------------------------------------------------------
    Kaynak:  https://docs.llamaindex.ai
    BaÅŸlÄ±k:  LLM'ler ve LlamaIndex HakkÄ±nda GerÃ§ekler
    AtÄ±f YapÄ±lan Ä°Ã§erik:
     
    BaÄŸlam
    LLM'ler, bilgi oluÅŸturma ve muhakeme iÃ§in olaÄŸanÃ¼stÃ¼ bir teknoloji parÃ§asÄ±dÄ±r.
    BÃ¼yÃ¼k miktarda halka aÃ§Ä±k veri Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸlerdir.
    LLM'leri kendi Ã¶zel verilerimizle en iyi nasÄ±l gÃ¼Ã§lendirebiliriz?
    LLM'ler iÃ§in bu veri gÃ¼Ã§lendirmesini gerÃ§ekleÅŸtirmeye yardÄ±mcÄ± olacak kapsamlÄ± bir araÃ§ setine ihtiyacÄ±mÄ±z var.
    
    Ã–nerilen Ã‡Ã¶zÃ¼m
    Ä°ÅŸte LlamaIndex burada devreye giriyor. LlamaIndex, LLM uygulamalarÄ± oluÅŸturmanÄ±za yardÄ±mcÄ± olacak bir "veri Ã§erÃ§evesidir". Åu araÃ§larÄ± saÄŸlar:
    
    Mevcut veri kaynaklarÄ±nÄ±zÄ± ve veri formatlarÄ±nÄ±zÄ± (API'ler, PDF'ler, belgeler, SQL vb.) almak iÃ§in veri baÄŸlayÄ±cÄ±larÄ± sunar.
    Verilerinizin LLM'lerle kolayca kullanÄ±labilmesi iÃ§in verilerinizi yapÄ±landÄ±rma yollarÄ± (indeksler, grafikler) saÄŸlar.
    Verileriniz Ã¼zerinde geliÅŸmiÅŸ bir eriÅŸim/sorgu arayÃ¼zÃ¼ saÄŸlar:
    Herhangi bir LLM giriÅŸ istemini besleyin, geri eriÅŸilen baÄŸlamÄ± ve bilgiyle gÃ¼Ã§lendirilmiÅŸ Ã§Ä±ktÄ±yÄ± alÄ±n.
    DÄ±ÅŸ uygulama Ã§erÃ§evenizle (Ã¶rneÄŸin LangChain, Flask, Docker, ChatGPT, baÅŸka herhangi bir ÅŸeyle) kolay entegrasyonlar saÄŸlar.
    LlamaIndex hem baÅŸlangÄ±Ã§ seviyesindeki kullanÄ±cÄ±lar hem de ileri dÃ¼zey kullanÄ±cÄ±lar iÃ§in araÃ§lar saÄŸlar.
    Ãœst dÃ¼zey API'miz, yeni baÅŸlayanlarÄ±n LlamaIndex'i kullanarak verilerini 5 satÄ±r kodla almalarÄ±na ve sorgulamalarÄ±na olanak tanÄ±r. Alt seviye API'lerimiz, ileri dÃ¼zey kullanÄ±cÄ±larÄ±n herhangi bir modÃ¼lÃ¼ (veri baÄŸlayÄ±cÄ±larÄ±, indeksler, alÄ±cÄ±lar, sorgu motorlarÄ±, yeniden sÄ±ralama modÃ¼lleri) ihtiyaÃ§larÄ±na gÃ¶re Ã¶zelleÅŸtirmesine ve geniÅŸletmesine olanak tanÄ±r.
    
    --------------------------------------------------------------------------------

### Manuel AraÃ§ Ã‡aÄŸÄ±rma + AtÄ±flar

AtÄ±f yapÄ±labilir bir blok dÃ¶ndÃ¼ren aracÄ±mÄ±zÄ± kullanarak, bir manuel aracÄ± dÃ¶ngÃ¼sÃ¼nde verilen araÃ§la LLM'i manuel olarak Ã§aÄŸÄ±rabiliriz.

LLM araÃ§ Ã§aÄŸÄ±rmayÄ± durdurduÄŸunda, nihai yanÄ±tÄ± dÃ¶ndÃ¼rebilir ve yanÄ±ttaki atÄ±flarÄ± ayrÄ±ÅŸtÄ±rabiliriz.

```python
from llama_index.core.llms import ChatMessage, CitationBlock

chat_history = [
    ChatMessage(
        role="system",
        # Statik bir sonuÃ§ dÃ¶ndÃ¼ren sahte bir aracÄ±mÄ±z olduÄŸu iÃ§in LLM belirteÃ§lerini boÅŸa harcamak istemiyoruz
        content="KullanÄ±cÄ± mesajÄ± baÅŸÄ±na yalnÄ±zca bir arama sorgusu yapÄ±n.",
    ),
    ChatMessage(
        role="user", content="LlamaIndex ve LLM'ler birlikte nasÄ±l Ã§alÄ±ÅŸÄ±r?"
    ),
]
resp = llm.chat_with_tools([search_tool], chat_history=chat_history)
chat_history.append(resp.message)

tool_calls = llm.get_tool_calls_from_response(
    resp, error_on_no_tool_call=False
)
while tool_calls:
    for tool_call in tool_calls:
        if tool_call.tool_name == "search_fn":
            tool_result = search_tool.call(tool_call.tool_kwargs)
            chat_history.append(
                ChatMessage(
                    role="tool",
                    blocks=tool_result.blocks,
                    additional_kwargs={"tool_call_id": tool_call.tool_id},
                )
            )

    resp = llm.chat_with_tools([search_tool], chat_history=chat_history)
    chat_history.append(resp.message)
    tool_calls = llm.get_tool_calls_from_response(
        resp, error_on_no_tool_call=False
    )

print(resp.message.content)
print("----" * 20)
for block in resp.message.blocks:
    if isinstance(block, CitationBlock):
        print("Kaynak: ", block.source)
        print("BaÅŸlÄ±k: ", block.title)
        print("AtÄ±f YapÄ±lan Ä°Ã§erik:\n", block.cited_content.text)
        print("----" * 20)
```

    Arama sonuÃ§larÄ±na dayanarak, LlamaIndex ve LLM'lerin birlikte nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± aÃ§Ä±klayabilirim:
    
    LlamaIndex, LLM uygulamalarÄ± oluÅŸturmanÄ±za yardÄ±mcÄ± olacak bir "veri Ã§erÃ§evesidir"
    . Entegrasyon, temel bir zorluÄŸu ele alarak Ã§alÄ±ÅŸÄ±r: 
    LLM'ler bilgi Ã¼retimi ve muhakeme iÃ§in olaÄŸanÃ¼stÃ¼ bir teknoloji parÃ§asÄ± olmalarÄ±na ve bÃ¼yÃ¼k miktarda halka aÃ§Ä±k veri Ã¼zerinde Ã¶nceden eÄŸitilmelerine raÄŸmen, LLM'leri kendi Ã¶zel verilerimizle gÃ¼Ã§lendirmek iÃ§in kapsamlÄ± bir araÃ§ setine ihtiyacÄ±mÄ±z vardÄ±r
    .
    
    LlamaIndex ve LLM'lerin birlikte Ã§alÄ±ÅŸma ÅŸekli ÅŸÃ¶yledir:
    
    ## Veri Entegrasyonu
    
    LlamaIndex, mevcut veri kaynaklarÄ±nÄ±zÄ± ve veri formatlarÄ±nÄ±zÄ± (API'ler, PDF'ler, belgeler, SQL vb.) almak iÃ§in veri baÄŸlayÄ±cÄ±larÄ± sunar
    , bu da Ã¶zel verilerinizi LLM'lerin Ã§alÄ±ÅŸabileceÄŸi bir formata getirmenizi saÄŸlar.
    
    ## Veri YapÄ±landÄ±rma
    
    LlamaIndex, bu verilerin LLM'lerle kolayca kullanÄ±labilmesi iÃ§in verilerinizi yapÄ±landÄ±rma yollarÄ± (indeksler, grafikler) saÄŸlar
    . Bu yapÄ±landÄ±rma, verilerinizin LLM tarafÄ±ndan eriÅŸilebilir ve taranabilir olmasÄ± iÃ§in Ã§ok Ã¶nemlidir.
    
    ## GeliÅŸmiÅŸ Sorgulama
    
    LlamaIndex, verileriniz Ã¼zerinde geliÅŸmiÅŸ bir eriÅŸim/sorgu arayÃ¼zÃ¼ saÄŸlar: Herhangi bir LLM giriÅŸ istemini besleyin, geri eriÅŸilen baÄŸlamÄ± ve bilgiyle gÃ¼Ã§lendirilmiÅŸ Ã§Ä±ktÄ±yÄ± alÄ±n
    . Bu, LLM'e bir soru sorduÄŸunuzda LlamaIndex'in verilerinizden ilgili bilgileri aldÄ±ÄŸÄ± ve LLM'in yanÄ±tÄ±nÄ± geliÅŸtirmek iÃ§in bunu baÄŸlam olarak sunduÄŸu anlamÄ±na gelir.
    
    ## Uygulama Entegrasyonu
    
    LlamaIndex, dÄ±ÅŸ uygulama Ã§erÃ§evenizle (Ã¶rneÄŸin LangChain, Flask, Docker, ChatGPT, baÅŸka herhangi bir ÅŸeyle) kolay entegrasyonlar saÄŸlar
    , bu da mevcut sistemlere dahil edilmesini esnek hale getirir.
    
    Ã‡erÃ§eve, farklÄ± seviyelerdeki kullanÄ±cÄ±lara eriÅŸilebilir olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r: 
    LlamaIndex'in Ã¼st dÃ¼zey API'si, yeni baÅŸlayanlarÄ±n verilerini 5 satÄ±r kodla almalarÄ±na ve sorgulamalarÄ±na olanak tanÄ±rken, alt seviye API'ler uzmanlarÄ±n ihtiyaÃ§larÄ±na gÃ¶re Ã¶zelleÅŸtirme yapmasÄ±na izin verir
    --------------------------------------------------------------------------------
    Kaynak:  https://docs.llamaindex.ai
    BaÅŸlÄ±k:  LLM'ler ve LlamaIndex HakkÄ±nda GerÃ§ekler
    AtÄ±f YapÄ±lan Ä°Ã§erik:
     
    BaÄŸlam
    LLM'ler, bilgi oluÅŸturma ve muhakeme iÃ§in olaÄŸanÃ¼stÃ¼ bir teknoloji parÃ§asÄ±dÄ±r.
    BÃ¼yÃ¼k miktarda halka aÃ§Ä±k veri Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸlerdir.
    LLM'leri kendi Ã¶zel verilerimizle en iyi nasÄ±l gÃ¼Ã§lendirebiliriz?
    LLM'ler iÃ§in bu veri gÃ¼Ã§lendirmesini gerÃ§ekleÅŸtirmeye yardÄ±mcÄ± olacak kapsamlÄ± bir araÃ§ setine ihtiyacÄ±mÄ±z var.
    
    Ã–nerilen Ã‡Ã¶zÃ¼m
    Ä°ÅŸte LlamaIndex burada devreye giriyor. LlamaIndex, LLM uygulamalarÄ± oluÅŸturmanÄ±za yardÄ±mcÄ± olacak bir "veri Ã§erÃ§evesidir". Åu araÃ§larÄ± saÄŸlar:
    
    Mevcut veri kaynaklarÄ±nÄ±zÄ± ve veri formatlarÄ±nÄ±zÄ± (API'ler, PDF'ler, belgeler, SQL vb.) almak iÃ§in veri baÄŸlayÄ±cÄ±larÄ± sunar.
    Verilerinizin LLM'lerle kolayca kullanÄ±labilmesi iÃ§in verilerinizi yapÄ±landÄ±rma yollarÄ± (indeksler, grafikler) saÄŸlar.
    Verileriniz Ã¼zerinde geliÅŸmiÅŸ bir eriÅŸim/sorgu arayÃ¼zÃ¼ saÄŸlar:
    Herhangi bir LLM giriÅŸ istemini besleyin, geri eriÅŸilen baÄŸlamÄ± ve bilgiyle gÃ¼Ã§lendirilmiÅŸ Ã§Ä±ktÄ±yÄ± alÄ±n.
    DÄ±ÅŸ uygulama Ã§erÃ§evenizle (Ã¶rneÄŸin LangChain, Flask, Docker, ChatGPT, baÅŸka herhangi bir ÅŸeyle) kolay entegrasyonlar saÄŸlar.
    LlamaIndex hem baÅŸlangÄ±Ã§ seviyesindeki kullanÄ±cÄ±lar hem de ileri dÃ¼zey kullanÄ±cÄ±lar iÃ§in araÃ§lar saÄŸlar.
    Ãœst dÃ¼zey API'miz, yeni baÅŸlayanlarÄ±n LlamaIndex'i kullanarak verilerini 5 satÄ±r kodla almalarÄ±na ve sorgulamalarÄ±na olanak tanÄ±r. Alt seviye API'lerimiz, ileri dÃ¼zey kullanÄ±cÄ±larÄ±n herhangi bir modÃ¼lÃ¼ (veri baÄŸlayÄ±cÄ±larÄ±, indeksler, alÄ±cÄ±lar, sorgu motorlarÄ±, yeniden sÄ±ralama modÃ¼lleri) ihtiyaÃ§larÄ±na gÃ¶re Ã¶zelleÅŸtirmesine ve geniÅŸletmesine olanak tanÄ±r.
    
    --------------------------------------------------------------------------------
