# CometAPI

CometAPI; GPT serisi, Claude serisi, Gemini serisi ve daha fazlasÄ±nÄ± iÃ§eren Ã§eÅŸitli son teknoloji LLM modellerine, OpenAI uyumlu birleÅŸik bir arayÃ¼z Ã¼zerinden eriÅŸim saÄŸlar. Daha fazla bilgiyi [ana sayfalarÄ±nda](https://www.cometapi.com/) bulabilirsiniz.

Kaydolmak ve bir API anahtarÄ± almak iÃ§in https://api.cometapi.com/console/token adresini ziyaret edin.

EÄŸer bu Not Defterini colab Ã¼zerinde aÃ§Ä±yorsanÄ±z, muhtemelen LlamaIndex'i ğŸ¦™ kurmanÄ±z gerekecektir.

```python
%pip install llama-index-llms-cometapi
```

```python
%pip install llama-index
```

```python
from llama_index.llms.cometapi import CometAPI
```

## ChatMessage Listesi ile `chat` Ã‡aÄŸrÄ±sÄ± YapÄ±n
`COMETAPI_API_KEY` ortam deÄŸiÅŸkenini ayarlamanÄ±z veya sÄ±nÄ±f yapÄ±cÄ±sÄ±nda (constructor) api_key'i belirtmeniz gerekir.

```python
import os

os.environ["COMETAPI_KEY"] = "<cometapi-anahtarÄ±nÄ±z>"

api_key = os.getenv("COMETAPI_KEY")
llm = CometAPI(
    api_key=api_key,
    max_tokens=256,
    context_window=4096,
    model="gpt-5-chat-latest",
)
```

```python
from llama_index.core.llms import ChatMessage

messages = [
    ChatMessage(role="system", content="YardÄ±msever bir asistansÄ±n"),
    ChatMessage(role="user", content="Sadece 'Selam' de!"),
]
resp = llm.chat(messages)
print(resp)
```

    assistant: Selam

```python
resp = llm.complete("Kaiming He kimdir?")
```

```python
print(resp)
```

    Kaiming He, bilgisayar gÃ¶rÃ¼sÃ¼ (computer vision) ve derin Ã¶ÄŸrenme alanÄ±ndaki etkili katkÄ±larÄ±yla tanÄ±nan Ã¼nlÃ¼ bir bilgisayar bilimcisi ve araÅŸtÄ±rma bilimcisidir. Ã–zellikle, CVPR 2016'da En Ä°yi Makale Ã–dÃ¼lÃ¼'nÃ¼ kazanan *"Deep Residual Learning for Image Recognition"* (2015) adlÄ± makalede tanÄ±tÄ±lan **ResNet** (ArtÄ±k AÄŸlar - Residual Networks) mimarisinin ana yazarlarÄ±ndan biri olmasÄ±yla tanÄ±nÄ±r. ResNet, artÄ±k baÄŸlantÄ±larÄ± (residual connections) kullanarak Ã§ok derin sinir aÄŸlarÄ±nÄ±n eÄŸitimini Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸtirmiÅŸ ve birÃ§ok gÃ¶rÃ¼ntÃ¼ iÅŸleme gÃ¶revi iÃ§in temel bir mimari haline gelmiÅŸtir.
    
    ### Kaiming He HakkÄ±nda Ã–nemli Bilgiler:
    
    - **EÄŸitim**:  
      Kaiming He, doktora derecesini Hong Kong Ã‡ince Ãœniversitesi'nden (CUHK) bilgisayar bilimleri alanÄ±nda almÄ±ÅŸtÄ±r. Burada Prof. Jian Sun ile Ã§alÄ±ÅŸmÄ±ÅŸ ve Visual Computing Group ile iÅŸ birliÄŸi yapmÄ±ÅŸtÄ±r.
    
    - **AraÅŸtÄ±rma Kariyeri**:
      - Microsoft Research Asia (MSRA) bÃ¼nyesinde Ã§alÄ±ÅŸmÄ±ÅŸtÄ±r.
      - Daha sonra Facebook AI Research (FAIR) bÃ¼nyesinde araÅŸtÄ±rma gÃ¶revlisi olarak yer almÄ±ÅŸtÄ±r.
      - Son yÄ±llarda, bilgisayar gÃ¶rÃ¼sÃ¼, derin Ã¶ÄŸrenme ve yapay zeka konularÄ±na odaklanarak FAIR (ÅŸimdi Meta AI'nÄ±n bir parÃ§asÄ±) bÃ¼nyesinde Ã§alÄ±ÅŸmalarÄ±nÄ± sÃ¼rdÃ¼rmektedir.
    
    - **BaÅŸlÄ±ca KatkÄ±lar**:
      - **ResNet** (Deep Residual Networks, 2015) â€” derin aÄŸlarda devrim yaratmÄ±ÅŸtÄ±r.

### AkÄ±ÅŸ (Streaming)

`stream_complete` bitiÅŸ noktasÄ±nÄ± (endpoint) kullanma

```python
message = ChatMessage(role="user", content="ResNet'in ne olduÄŸunu anlat")
resp = llm.stream_chat([message])
for r in resp:
    print(r.delta, end="")
```

    ResNet, **Residual Network** (ArtÄ±k AÄŸ) ifadesinin kÄ±saltmasÄ±dÄ±r ve Microsoft Research tarafÄ±ndan 2015 yÄ±lÄ±nda Kaiming He ve arkadaÅŸlarÄ± tarafÄ±ndan hazÄ±rlanan *"Deep Residual Learning for Image Recognition"* makalesinde tanÄ±tÄ±lan bir derin sinir aÄŸÄ± mimarisi tÃ¼rÃ¼dÃ¼r. **ImageNet Large Scale Visual Recognition Challenge ( al. It became famous after winning the **ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2015**. mimarisi, 2015 yÄ±lÄ±nda dÃ¼zenlenen **ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2015** yarÄ±ÅŸmasÄ±nÄ± kazandÄ±ktan sonra Ã¼nlenmiÅŸtir.
    
    ---
    
    ### **Temel fikir**
    ResNet'in en bÃ¼yÃ¼k yeniliÄŸi,ILSVRC) 2015**. **atlamalÄ± baÄŸlantÄ±lar** (veya kestirme baÄŸlantÄ±lar - skip connections) kullanan **artÄ±k Ã¶ÄŸrenme** (residual learning) kavramÄ±dÄ±r. Ã‡ok derin derin sinir aÄŸlarÄ±nda, **yok olan/patlayan gradyan sorunu** ve optimizasyon zorluklarÄ± nedeniyle performans dÃ¼ÅŸebilir. ResNet, belirli katmanlarÄ±n aÄŸ iÃ§inde Ã¶zdeÅŸlik eÅŸlemeleri (identity mappings) aracÄ±lÄ±ÄŸÄ±yla ileriye "atlamasÄ±na" izin vererek bu sorunu Ã§Ã¶zer.
    
    Bir *artÄ±k blok* (residual block) ÅŸuna benzer:
    
    ```
    Girdi â†’ [Katman(lar): Conv, BatchNorm, ReLU] â†’ Ã‡Ä±ktÄ±
       \_____________________________________/
                      (atlamalÄ± baÄŸlantÄ±)
    ```
    
    BaÄŸlantÄ± aracÄ±lÄ±ÄŸÄ±yla doÄŸrudan bir \( H(x) \) eÅŸlemesini Ã¶ÄŸrenmek yerine, artÄ±k blok \( F(x) = H(x) - x \) Ã¶ÄŸrenir, bÃ¶ylece:
    \[
    H(x) = F(x) + x
    \]
    Burada \( x \), bloÄŸun Ã§Ä±ktÄ±sÄ±na doÄŸrudan eklenerek daha kolay gradyan akÄ±ÅŸÄ± saÄŸlar ve aÄŸÄ±n eÄŸitimine olanak tanÄ±r.

```python
resp = llm.stream_complete("Bana BÃ¼yÃ¼k Dil Modellerinden (LLM) bahset")
```

```python
for r in resp:
    print(r.delta, end="")
```

    Tabii! **BÃ¼yÃ¼k Dil Modelleri** (BÃ¼yÃ¼k Dil Modelleri - LLMs), insan dilini anlamak, oluÅŸturmak ve manipÃ¼le etmek iÃ§in tasarlanmÄ±ÅŸ bir tÃ¼r **yapay zeka modeli**dir. Kitaplar, makaleler, web siteleri, kodlar ve daha fazlasÄ±ndan oluÅŸan devasa miktardaki metin verileriyle eÄŸitilirler; bu da bir isteme (prompt) dayalÄ± olarak tutarlÄ± metinler tahmin etmelerini ve Ã¼retmelerini saÄŸlar.
    
    Ä°ÅŸte ayrÄ±ntÄ±lÄ± bir genel bakÄ±ÅŸ:
    
    ---
    
    ## **1. Nedirler?**
    - LLM'ler, genellikle 2017 yÄ±lÄ±nda *Vaswani ve arkadaÅŸlarÄ±* tarafÄ±ndan *"Attention Is All You Need"* makalesinde tanÄ±tÄ±lan **transformer mimarisine** dayanan **derin Ã¶ÄŸrenme** modellerinin bir alt kÃ¼mesidir.
    - Bunlara *"bÃ¼yÃ¼k"* denilmesinin sebebi, milyarlarca hatta trilyonlarca **parametreye** (eÄŸitim sÄ±rasÄ±nda Ã¶ÄŸrenilen ayarlanabilir aÄŸÄ±rlÄ±klar) sahip olmalarÄ± ve devasa veri kÃ¼meleri Ã¼zerinde eÄŸitilmeleridir.
    
    ---
    
    ## **2. NasÄ±l Ã‡alÄ±ÅŸÄ±rlar?**
    1. **EÄŸitim Verileri**  
       Kitaplar, Wikipedia, internet vb. kaynaklardan alÄ±nan devasa metin kÃ¼lliyatlarÄ±ndan (corpora) dil kalÄ±plarÄ±nÄ± Ã¶ÄŸrenirler.
    2. **Tokenizasyon**  
       Metin, *token* adÄ± verilen kÃ¼Ã§Ã¼k parÃ§alara (bunlar kelimelerin tamamÄ±, alt kelimeler veya karakterler olabilir) bÃ¶lÃ¼nÃ¼r.
    3. **Sinirsel Mimari**  
       Transformer'lar, farklÄ± bÃ¶lÃ¼mler arasÄ±ndaki iliÅŸkileri kurmak iÃ§in *Ã¶z-dikkat* (self-attention) mekanizmalarÄ±nÄ± kullanÄ±rlar.

### FarklÄ± Modellerin KullanÄ±mÄ±

CometAPI; GPT, Claude ve Gemini serileri dahil olmak Ã¼zere Ã§eÅŸitli yapay zeka modellerini destekler.

```python
# Claude modelini kullanma
claude_llm = CometAPI(
    api_key=api_key, model="claude-3-7-sonnet-latest", max_tokens=200
)

resp = claude_llm.complete("Derin Ã¶ÄŸrenmeyi kÄ±saca aÃ§Ä±kla")
print(resp)
```

    # Derin Ã–ÄŸrenme: KÄ±sa Bir AÃ§Ä±klama
    
    Derin Ã¶ÄŸrenme, verileri analiz etmek ve tahminlerde bulunmak iÃ§in Ã§ok katmanlÄ± (bu yÃ¼zden "derin") sinir aÄŸlarÄ±nÄ± kullanan makine Ã¶ÄŸreniminin bir alt kÃ¼mesidir.
    
    ## Temel Ã–zellikler:
    
    - **Sinir AÄŸlarÄ±**: Ä°nsan beyninden esinlenen bu aÄŸlar, katmanlar halinde organize edilmiÅŸ birbirine baÄŸlÄ± dÃ¼ÄŸÃ¼mlerden (nÃ¶ronlar) oluÅŸur.
    - **Otomatik Ã–zellik Ã‡Ä±karÄ±mÄ±**: Geleneksel makine Ã¶ÄŸreniminin aksine, derin Ã¶ÄŸrenme, manuel mÃ¼hendislik olmadan verilerdeki Ã¶nemli Ã¶zellikleri otomatik olarak keÅŸfeder.
    - **HiyerarÅŸik Ã–ÄŸrenme**: Alt katmanlar basit kalÄ±plarÄ± Ã¶ÄŸrenirken, daha derin katmanlar bunlarÄ± birleÅŸtirerek karmaÅŸÄ±k kavramlarÄ± tanÄ±r.
    - **BÃ¼yÃ¼k Veri Gereksinimi**: Genellikle iyi performans gÃ¶stermek iÃ§in Ã¶nemli miktarda veriye ihtiyaÃ§ duyar.
    
    Derin Ã¶ÄŸrenme; gÃ¶rÃ¼ntÃ¼ tanÄ±ma, doÄŸal dil iÅŸleme, konuÅŸma tanÄ±ma ve Ã¶neri sistemleri dahil olmak Ã¼zere birÃ§ok modern teknolojinin temelini oluÅŸturur. EtkinliÄŸi, verilerdeki son derece karmaÅŸÄ±k iliÅŸkileri modelleme yeteneÄŸinden gelir, ancak bu genellikle Ã¶nemli hesaplama kaynaklarÄ± gerektirir.
